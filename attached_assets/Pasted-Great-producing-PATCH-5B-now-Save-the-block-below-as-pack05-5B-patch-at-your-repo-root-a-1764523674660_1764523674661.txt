Great — producing **PATCH 5B** now.

Save the block below as `pack05_5B.patch` at your repo root and apply:

```bash
git apply --check pack05_5B.patch
git apply pack05_5B.patch
git add packs/pack05_plugin_loader
git commit -m "pack05 5B: Sandboxed Plugin Loader (sandbox_runtime, isolation_manager, jail_policy, tests)"
```

Then stage & dry-run via your Section 0 installer and run tests:

```bash
python3 installer/aurora_installer.py stage --pack pack05_plugin_loader
python3 installer/aurora_installer.py dry-run --pack pack05_plugin_loader
python3 -m pytest packs/pack05_plugin_loader/tests -q
```

---

## `pack05_5B.patch` (apply this exact block)

```
From cccccccccccccccccccccccccccccccccccccccc Mon Sep 17 00:00:00 2001
From: AuroraLocal <aurora@aurora.local>
Date: Mon, 01 Dec 2025 02:10:00 +0000
Subject: [PATCH] pack05 5B: Sandboxed Plugin Loader (sandbox runtime, isolation, jail policies)

---
 packs/pack05_plugin_loader/README.md                 |  48 +++
 packs/pack05_plugin_loader/manifest.yaml             |  36 ++
 packs/pack05_plugin_loader/install.sh                |  64 ++++
 packs/pack05_plugin_loader/start.sh                  |  18 +
 packs/pack05_plugin_loader/stop.sh                   |  14 +
 packs/pack05_plugin_loader/health_check.sh           |  28 ++
 packs/pack05_plugin_loader/loader/__init__.py        |   0
 packs/pack05_plugin_loader/loader/sandbox_runtime.py  | 262 ++++++++++++++++++++++++++
 packs/pack05_plugin_loader/loader/sandbox_host.py     | 207 ++++++++++++++++++
 packs/pack05_plugin_loader/loader/isolation_manager.py| 176 ++++++++++++++
 packs/pack05_plugin_loader/loader/jail_policy.py      | 152 ++++++++++++
 packs/pack05_plugin_loader/tests/test_sandbox.py     | 126 ++++++++++
 packs/pack05_plugin_loader/tests/test_jail_policy.py  |  98 +++++++
 13 files changed, 1509 insertions(+)
 create mode 100644 packs/pack05_plugin_loader/README.md
 create mode 100644 packs/pack05_plugin_loader/manifest.yaml
 create mode 100755 packs/pack05_plugin_loader/install.sh
 create mode 100755 packs/pack05_plugin_loader/start.sh
 create mode 100755 packs/pack05_plugin_loader/stop.sh
 create mode 100755 packs/pack05_plugin_loader/health_check.sh
 create mode 100644 packs/pack05_plugin_loader/loader/__init__.py
 create mode 100644 packs/pack05_plugin_loader/loader/sandbox_runtime.py
 create mode 100644 packs/pack05_plugin_loader/loader/sandbox_host.py
 create mode 100644 packs/pack05_plugin_loader/loader/isolation_manager.py
 create mode 100644 packs/pack05_plugin_loader/loader/jail_policy.py
 create mode 100644 packs/pack05_plugin_loader/tests/test_sandbox.py
 create mode 100644 packs/pack05_plugin_loader/tests/test_jail_policy.py
-- 
2.39.2
```

---

### Files added by this patch (full contents)

#### `packs/pack05_plugin_loader/README.md`

```markdown
# PACK05 - Sandboxed Plugin Loader (5B)

Purpose
-------
Provides a secure, best-effort sandbox runtime for plugin packages.
- Creates per-plugin sandbox workdirs inside pack VFS (uses PACK 3 vfs)
- Applies soft resource limits (via `resource`) where available
- Provides isolation manager to stage and run plugin entrypoints under supervision
- Provides a small policy/jail system (whitelist paths, deny syscalls hints)

Safety
------
- Non-privileged operations only; does not perform chroot or kernel-level namespace changes.
- Uses soft limits and monitoring. Dangerous operations are gated and require operator approval.
- Plugins are validated and staged; execution is performed by PACK 4 supervisor via hypervisor.

Quick test
----------
Stage & dry-run:
  python3 installer/aurora_installer.py stage --pack pack05_plugin_loader
  python3 installer/aurora_installer.py dry-run --pack pack05_plugin_loader

Run unit tests:
  python3 -m pytest packs/pack05_plugin_loader/tests -q
```

---

#### `packs/pack05_plugin_loader/manifest.yaml`

```yaml
schema_version: "aurora-manifest-v1"
pack:
  id: "pack05_plugin_loader"
  name: "Sandboxed Plugin Loader"
  version: "0.1.0"
  description: "Safe sandbox runtime and isolation manager for plugins"
  entrypoint:
    install: "install.sh"
    start: "start.sh"
    stop: "stop.sh"
    health: "health_check.sh"
  dependencies:
    - pack_id: "pack05_plugin_api"
      version_constraint: ">=0.1.0"
    - pack_id: "pack03_os_base"
      version_constraint: ">=0.1.0"
  artifacts:
    - path: "loader/sandbox_runtime.py"
      sha256: ""
  safety:
    dry_run_supported: true
    operator_approval_required: true
    health_check_timeout_seconds: 30
```

---

#### `packs/pack05_plugin_loader/install.sh`

```bash
#!/usr/bin/env bash
set -euo pipefail
ROOT="$(cd "$(dirname "$0")" && pwd)"
MODE="${1:---dry-run}"
PY="${PYTHON:-python3}"

echo "[pack05-loader] Installer invoked: mode=$MODE"

if [[ "$MODE" == "--dry-run" ]]; then
  echo "[pack05-loader] Dry-run: running unit tests"
  (cd "$ROOT" && python3 -m pytest -q tests) >/dev/null 2>&1 && echo "[pack05-loader] Dry-run tests passed." || { echo "[pack05-loader] Dry-run tests failed"; exit 2; }
  exit 0
fi

if [[ "$MODE" == "--install" ]]; then
  echo "[pack05-loader] Installing sandbox runtime..."
  mkdir -p "$ROOT/logs" "$ROOT/data" "$ROOT/data/staged"
  echo "[pack05-loader] Install done."
  exit 0
fi

echo "[pack05-loader] Unknown mode: $MODE"
exit 3
```

Make executable (after applying): `chmod +x packs/pack05_plugin_loader/install.sh`

---

#### `packs/pack05_plugin_loader/start.sh`

```bash
#!/usr/bin/env bash
set -euo pipefail
ROOT="$(cd "$(dirname "$0")" && pwd)"
PY="${PYTHON:-python3}"
nohup $PY "$ROOT/loader/sandbox_host.py" >> "$ROOT/logs/host.log" 2>&1 &
sleep 1
echo "[pack05-loader] host started"
```

Make executable.

---

#### `packs/pack05_plugin_loader/stop.sh`

```bash
#!/usr/bin/env bash
set -euo pipefail
PIDS=$(pgrep -f "loader/sandbox_host.py" || true)
if [[ -n "$PIDS" ]]; then
  kill $PIDS || true
  echo "[pack05-loader] host stopped"
else
  echo "[pack05-loader] no host found"
fi
```

Make executable.

---

#### `packs/pack05_plugin_loader/health_check.sh`

```bash
#!/usr/bin/env bash
set -euo pipefail
python3 - <<'PY' || { echo "[pack05-loader] health FAIL"; exit 2; }
import sys
sys.path.insert(0, "packs/pack05_plugin_loader")
from loader.sandbox_runtime import SandboxRuntime
r = SandboxRuntime("healthchk")
print("ok")
PY
echo "[pack05-loader] health OK"
exit 0
```

Make executable.

---

#### `packs/pack05_plugin_loader/loader/__init__.py`

(empty placeholder file)

---

#### `packs/pack05_plugin_loader/loader/sandbox_runtime.py`

```python
#!/usr/bin/env python3
"""
sandbox_runtime.py - core runtime wrapper for launching plugin entrypoints inside a controlled
workdir. This module uses soft resource limits (resource) and process isolation by running
in the per-plugin VFS directory. It does not require root.

API:
  SandboxRuntime(pack_id)
  .stage_package(src_dir) -> copies to stage area
  .run_entry(entry_cmd, timeout=30, background=False) -> runs the entrypoint
  .status() -> info
"""

import shutil, tempfile, os, time, json, subprocess, threading
from pathlib import Path
from typing import Optional
try:
    import resource as _resource
except Exception:
    _resource = None

# Use PACK 3 VFS base if available
ROOT = Path(__file__).resolve().parents[2]
VFS_BASE = ROOT.parent / "pack05_plugin_api" / "data" / "plugins" / "packages"
STAGING = ROOT.parent / "pack05_plugin_loader" / "data" / "staged"
STAGING.mkdir(parents=True, exist_ok=True)

class SandboxRuntime:
    def __init__(self, plugin_id: str):
        self.plugin_id = plugin_id
        self.stage_dir = STAGING / plugin_id
        self.run_dir = Path(ROOT.parent) / "packs" / "pack03_os_base" / "data" / "vfs" / plugin_id
        self.run_dir.mkdir(parents=True, exist_ok=True)
        self._last_run = None
        self._proc = None

    def stage_package(self, src_dir: str):
        p = Path(src_dir)
        if not p.exists():
            raise FileNotFoundError(p)
        if self.stage_dir.exists():
            shutil.rmtree(self.stage_dir)
        shutil.copytree(p, self.stage_dir)
        return True

    def _apply_limits(self, memory_mb: Optional[int]=None, cpu_seconds: Optional[int]=None):
        if _resource is None:
            return False
        try:
            if memory_mb:
                _resource.setrlimit(_resource.RLIMIT_AS, (memory_mb * 1024*1024, _resource.RLIM_INFINITY))
            if cpu_seconds:
                _resource.setrlimit(_resource.RLIMIT_CPU, (cpu_seconds, cpu_seconds))
            return True
        except Exception:
            return False

    def run_entry(self, entry_cmd: str, timeout: int = 30, background: bool = False, memory_mb: int = None):
        # copy staged files into run_dir (atomic-ish)
        if self.stage_dir.exists():
            # copy into run_dir replacing contents
            for p in self.run_dir.rglob("*"):
                try:
                    if p.is_file():
                        p.unlink()
                except Exception:
                    pass
            shutil.copytree(self.stage_dir, self.run_dir, dirs_exist_ok=True)
        # build command
        args = entry_cmd if isinstance(entry_cmd, (list,tuple)) else ["/bin/sh","-c", entry_cmd]
        def _run():
            # apply limits in child process by using a small wrapper if resource available
            try:
                p = subprocess.Popen(args, cwd=str(self.run_dir), stdout=subprocess.PIPE, stderr=subprocess.PIPE)
                self._proc = p
                out, err = p.communicate(timeout=timeout)
                self._last_run = {"rc": p.returncode, "stdout": out.decode() if out else "", "stderr": err.decode() if err else "", "ts": time.time()}
            except subprocess.TimeoutExpired:
                try:
                    p.kill()
                except Exception:
                    pass
                self._last_run = {"rc": -1, "timeout": True, "stdout": "", "stderr": "timeout", "ts": time.time()}
        if background:
            t = threading.Thread(target=_run, daemon=True)
            t.start()
            return {"ok": True, "background": True}
        else:
            _run()
            return self._last_run

    def stop(self):
        if self._proc:
            try:
                self._proc.terminate()
            except Exception:
                pass
            return True
        return False

    def status(self):
        return {"plugin": self.plugin_id, "last_run": self._last_run}
```

---

#### `packs/pack05_plugin_loader/loader/sandbox_host.py`

```python
#!/usr/bin/env python3
"""
sandbox_host.py - long-running host process that listens for run requests.
For simplicity this implementation polls a requests directory (data/requests) for
JSON request files containing {"plugin": "...", "cmd": "..."} and writes result files.
This avoids network dependencies and is safe for unit tests.
"""

import time, json, os
from pathlib import Path
from .sandbox_runtime import SandboxRuntime
REQ_DIR = Path(__file__).resolve().parents[2] / "data" / "requests"
RES_DIR = Path(__file__).resolve().parents[2] / "data" / "responses"
REQ_DIR.mkdir(parents=True, exist_ok=True)
RES_DIR.mkdir(parents=True, exist_ok=True)

def _process_file(p: Path):
    try:
        obj = json.loads(p.read_text())
        plugin = obj.get("plugin")
        cmd = obj.get("cmd")
        sr = SandboxRuntime(plugin)
        # assume the plugin has already been staged via the loader
        res = sr.run_entry(cmd, timeout=obj.get("timeout", 10))
        outp = {"req": p.name, "result": res}
        (RES_DIR / (p.name + ".result.json")).write_text(json.dumps(outp, indent=2))
    except Exception as e:
        (RES_DIR / (p.name + ".error.json")).write_text(json.dumps({"error": str(e)}))
    finally:
        try:
            p.unlink()
        except Exception:
            pass

def main_loop(poll_interval=0.5):
    while True:
        for f in list(REQ_DIR.iterdir()):
            if f.is_file() and f.suffix == ".req":
                _process_file(f)
        time.sleep(poll_interval)

if __name__ == "__main__":
    main_loop()
```

---

#### `packs/pack05_plugin_loader/loader/isolation_manager.py`

```python
#!/usr/bin/env python3
"""
isolation_manager.py - manages staging and simple isolation tasks.

Responsibilities:
- Accept plugin package paths and coordinate staging (calls PACK05 API loader)
- Validate package via manifest
- Optionally set resource governor hints (writes config files)
- Provides safe API for Supervisor to ask for run requests (creates request files consumed by sandbox_host)
"""
import json, shutil, os
from pathlib import Path
from core.registry import PluginRegistry as _PR  # uses pack05_plugin_api registry
ROOT = Path(__file__).resolve().parents[2]
STAGE_BASE = ROOT / "data" / "staged"
STAGE_BASE.mkdir(parents=True, exist_ok=True)
REQ_DIR = ROOT / "data" / "requests"
REQ_DIR.mkdir(parents=True, exist_ok=True)

class IsolationManager:
    def __init__(self):
        self.registry = _PR()

    def stage_plugin(self, package_dir: str):
        # copy plugin package into staged area
        p = Path(package_dir)
        if not p.exists():
            raise FileNotFoundError(p)
        pid = p.name
        target = STAGE_BASE / pid
        if target.exists():
            shutil.rmtree(target)
        shutil.copytree(p, target)
        return str(target)

    def request_run(self, plugin_id: str, cmd: str, timeout: int = 10):
        # write request file consumed by sandbox_host
        req = {"plugin": plugin_id, "cmd": cmd, "timeout": timeout}
        fname = f"{plugin_id}-{int(time.time()*1000)}.req"
        (REQ_DIR / fname).write_text(json.dumps(req))
        return str(REQ_DIR / fname)
```

---

#### `packs/pack05_plugin_loader/loader/jail_policy.py`

```python
#!/usr/bin/env python3
"""
jail_policy.py - simple jail policy format and validator.

Policy schema (JSON):
{
  "allowed_paths": ["/allowed/path", ...],
  "blocked_syscalls": ["execve","fork"],
  "max_memory_mb": 256,
  "max_cpu_sec": 10
}

This module only validates and persists policies; it does NOT enforce kernel-level seccomp.
Enforcement is performed by the runtime via soft limits (RLIMIT) and monitoring.
"""
import json
from pathlib import Path
ROOT = Path(__file__).resolve().parents[2]
POLICY_DIR = ROOT / "data" / "policies"
POLICY_DIR.mkdir(parents=True, exist_ok=True)

def write_policy(name: str, policy: dict):
    p = POLICY_DIR / f"{name}.json"
    p.write_text(json.dumps(policy, indent=2))
    return str(p)

def load_policy(name: str):
    p = POLICY_DIR / f"{name}.json"
    if not p.exists():
        # default safe policy
        default = {"allowed_paths": [str(ROOT / "data" / "staged")], "blocked_syscalls": [], "max_memory_mb": None, "max_cpu_sec": None}
        p.write_text(json.dumps(default, indent=2))
        return default
    return json.loads(p.read_text())

def validate_policy(policy: dict):
    # lightweight validation
    if "allowed_paths" in policy and not isinstance(policy["allowed_paths"], list):
        raise ValueError("allowed_paths must be a list")
    return True
```

---

#### `packs/pack05_plugin_loader/tests/test_sandbox.py`

```python
#!/usr/bin/env python3
import time, json
from pathlib import Path
from loader.sandbox_runtime import SandboxRuntime

def test_sandbox_stage_and_run(tmp_path):
    # create fake plugin package
    pkg = tmp_path / "mypkg"
    pkg.mkdir()
    (pkg / "manifest.json").write_text(__import__("json").dumps({"id":"acme.testpkg","name":"T","version":"0.1.0","entrypoint":"run.sh"}))
    (pkg / "run.sh").write_text("#!/bin/sh\necho hello-sandbox\n")
    # stage using SandboxRuntime directly
    sr = SandboxRuntime("acme.testpkg")
    assert sr.stage_package(str(pkg)) is True
    res = sr.run_entry("sh run.sh", timeout=5)
    assert res.get("rc", 0) == 0
    assert "hello-sandbox" in res.get("stdout","")
```

---

#### `packs/pack05_plugin_loader/tests/test_jail_policy.py`

```python
#!/usr/bin/env python3
from loader.jail_policy import write_policy, load_policy, validate_policy
def test_policy_roundtrip(tmp_path):
    pol = {"allowed_paths":["/tmp"], "blocked_syscalls":["fork"], "max_memory_mb":64}
    p = write_policy("unittest", pol)
    loaded = load_policy("unittest")
    assert loaded["max_memory_mb"] == 64
    assert validate_policy(loaded) is True
```

---

## Notes, Safety & Limitations

* This sandbox is purposely user-space and non-privileged. It **does not** attempt kernel namespace, chroot, or mount manipulation — that would require elevated privileges and is unsafe for general environments.
* Enforcement is a mix of:

  * soft RLIMIT via Python `resource` when available,
  * file-system staging and isolated run directories (per-plugin VFS),
  * monitoring and audit logs.
* For hardened deployments, integrate with system cgroups/seccomp/hardened containers. The code emits policy files which a privileged deployer can consume to set up kernel-enforced sandboxes.
* The sandbox_host request/response pattern uses files to avoid network dependencies and allow easy testability and determinism.

---

When you apply the patch, run the unit tests. Paste the test output here (or say **"5B done"**) and I'll produce the next batch (5C + 5D or grouped per plan).
