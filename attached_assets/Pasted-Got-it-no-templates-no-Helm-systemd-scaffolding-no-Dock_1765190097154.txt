Got it — no templates, no Helm/systemd scaffolding, no Docker-specific bits. Aurora is pure scratch-first code and should run *anywhere*. I'll switch focus to a single, self-contained, production-ready runtime file that:

* has **no templates** or orchestration manifests embedded,
* uses the included `etcd_store.py` for registry + locks,
* uses the **containerless** sandbox runner (`sandbox_runner_no_docker.py`) for isolation,
* wires everything into `AutonomyManager` cleanly,
* exposes a small CLI + function entrypoint you can call from your own launcher (or embed in Aurora's event loop).

# TL;DR

I created a single production-ready file you can drop into the repo as:

`aurora_nexus_v3/autonomy/prod_autonomy_nontemplated.py`

It integrates `etcd_store` + `sandbox_runner_no_docker` + `manager.AutonomyManager`. No Docker, no templates, no external deployment assumptions — pure code. Use it directly from CLI or call `handle_incident_and_return()` from your event bus.

# Plan / pseudocode

1. Read registry using `etcd_store.get_registry()` (fallback already in etcd_store).
2. Generator: call `tools.generate_modules.generate_module_files()` if available, else fall back to CLI generator — same as before but no Docker expectations.
3. Inspector: AST + compile checks.
4. Tester: find `*_execute.py` and call `sandbox_runner_no_docker.run_module_candidate()` with resource limits and timeout.
5. Snapshot: git-based snapshot via `git commit` (same approach) — returns commit hash.
6. Promote: acquire lock via `etcd_store.acquire_lock()` and atomically write registry with `etcd_store.put_registry_atomic()`. Move files into `aurora_nexus_v3/modules/...` with safe backups.
7. Notify, sign, audit: plain file-based audit and approvals directory.
8. Expose `build_prod_autonomy_manager()` and `handle_incident_and_return()` CLI.

---

# Production-ready file

Paste the single file below to `aurora_nexus_v3/autonomy/prod_autonomy_nontemplated.py`. It assumes companion modules `aurora_nexus_v3/autonomy/etcd_store.py`, `aurora_nexus_v3/autonomy/sandbox_runner_no_docker.py`, `aurora_nexus_v3/autonomy/manager.py`, and `tools/generate_modules.py` exist (they are included in the bundle).

```python
# File: aurora_nexus_v3/autonomy/prod_autonomy_nontemplated.py
"""
Production Autonomy Adapter — No templates, no Docker, universal runtime.

Drop this into aurora_nexus_v3/autonomy/ and call handle_incident_and_return()
or wire build_prod_autonomy_manager() into your runtime.

Relies on:
 - aurora_nexus_v3.autonomy.etcd_store: get_registry(), put_registry_atomic(), acquire_lock()
 - aurora_nexus_v3.autonomy.sandbox_runner_no_docker: run_module_candidate()
 - aurora_nexus_v3.autonomy.manager: AutonomyManager, Incident, RepairResult
 - tools.generate_modules: generate_module_files(...) OR CLI fallback at tools/generate_modules.py
"""
from __future__ import annotations
import json, logging, os, shutil, subprocess, sys, tempfile, time, uuid
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional

from aurora_nexus_v3.autonomy.manager import AutonomyManager, Incident, RepairResult
from aurora_nexus_v3.autonomy import etcd_store
from aurora_nexus_v3.autonomy import sandbox_runner_no_docker as sandbox_runner

# Configuration (tune as needed)
REPO_ROOT = Path.cwd()
MODULES_DIR = REPO_ROOT / "aurora_nexus_v3" / "modules"
GENERATED_STAGE = REPO_ROOT / "aurora_nexus_v3" / "generated_candidates"
AUDIT_LOG = REPO_ROOT / "aurora_nexus_v3" / "autonomy_audit.log"
APPROVALS_DIR = REPO_ROOT / "aurora_nexus_v3" / "autonomy_approvals"
GENERATOR_CLI = [sys.executable, str(REPO_ROOT / "tools" / "generate_modules.py")]
SANDBOX_TIMEOUT_SEC = int(os.environ.get("SANDBOX_TIMEOUT_SEC", "20"))
SANDBOX_MEM_MB = int(os.environ.get("SANDBOX_MEM_MB", "256"))
SANDBOX_CPU_SECONDS = int(os.environ.get("SANDBOX_CPU_SECONDS", "5"))
SANDBOX_NOFILE = int(os.environ.get("SANDBOX_NOFILE", "512"))
WORKER_POOL = int(os.environ.get("AUTONOMY_WORKERS", "6"))

# Logging
logger = logging.getLogger("prod_autonomy_nontemplated")
if not logger.handlers:
    h = logging.StreamHandler()
    h.setFormatter(logging.Formatter("[%(asctime)s] %(levelname)s %(name)s: %(message)s"))
    logger.addHandler(h)
logger.setLevel(logging.INFO)

# Ensure dirs
GENERATED_STAGE.mkdir(parents=True, exist_ok=True)
APPROVALS_DIR.mkdir(parents=True, exist_ok=True)
AUDIT_LOG.parent.mkdir(parents=True, exist_ok=True)

def audit_log(entry: Dict[str, Any]) -> None:
    record = {"ts": datetime.utcnow().isoformat() + "Z", **entry}
    with AUDIT_LOG.open("a", encoding="utf-8") as f:
        f.write(json.dumps(record, default=str) + "\n")
    logger.info("AUDIT: %s", entry.get("action"))

# Registry helpers (use etcd adapter, fallback inside etcd_store)
def read_registry() -> dict:
    try:
        return etcd_store.get_registry()
    except Exception:
        logger.exception("etcd_store.get_registry failed; fallback to local file")
        fallback = REPO_ROOT / "aurora_nexus_v3" / "modules_registry.json"
        if fallback.exists():
            try:
                return json.loads(fallback.read_text(encoding="utf-8"))
            except Exception:
                logger.exception("fallback registry read failed")
        return {}

def atomic_registry_update(updater_func):
    ok, new = etcd_store.put_registry_atomic(updater_func)
    if not ok:
        raise RuntimeError("atomic registry update failed")
    return new

# Generator: prefer importable API, fallback to CLI
def generator_adapter(manifest_entry: Dict[str, Any]) -> str:
    candidate_id = f"{manifest_entry.get('id')}_{uuid.uuid4().hex[:8]}"
    candidate_dir = GENERATED_STAGE / candidate_id
    candidate_dir.mkdir(parents=True, exist_ok=True)
    # try importable
    try:
        import importlib
        gen_mod = None
        try:
            gen_mod = importlib.import_module("tools.generate_modules")
        except Exception:
            gen_mod = None
        if gen_mod and hasattr(gen_mod, "generate_module_files"):
            temp_manifest = candidate_dir / "modules.manifest.json"
            temp_manifest.write_text(json.dumps({"modules": [manifest_entry]}, indent=2), encoding="utf-8")
            gen_mod.generate_module_files(temp_manifest, candidate_dir / "modules", dry_run=False, force=True, update_init=False)
            audit_log({"action": "generate_api", "module_id": manifest_entry.get("id"), "candidate": str(candidate_dir)})
            return str(candidate_dir)
    except Exception:
        logger.exception("Generator API path failed; falling back to CLI")
    # CLI fallback
    try:
        temp_manifest = candidate_dir / "modules.manifest.json"
        temp_manifest.write_text(json.dumps({"modules": [manifest_entry]}, indent=2), encoding="utf-8")
        cmd = GENERATOR_CLI + ["--manifest", str(temp_manifest), "--out", str(candidate_dir / "modules"), "--force"]
        logger.info("Running generator CLI: %s", " ".join(cmd))
        subprocess.check_call(cmd, cwd=str(REPO_ROOT))
        audit_log({"action": "generate_cli", "module_id": manifest_entry.get("id"), "candidate": str(candidate_dir)})
        return str(candidate_dir)
    except subprocess.CalledProcessError as e:
        logger.exception("Generator CLI failed: %s", e)
        raise

# Inspector: AST + compile
def inspector_adapter(candidate_path: str) -> Dict[str, Any]:
    import ast
    p = Path(candidate_path)
    modules_subdir = p / "modules"
    if not modules_subdir.exists():
        return {"ok": False, "issues": ["modules subdir missing"]}
    issues = []
    files_checked = 0
    for py in modules_subdir.rglob("*.py"):
        try:
            source = py.read_text(encoding="utf-8")
            ast.parse(source)
            compile(source, str(py), "exec")
            files_checked += 1
        except SyntaxError as se:
            issues.append(f"SyntaxError in {py}: {se}")
        except Exception as e:
            issues.append(f"Static-check failed for {py}: {type(e).__name__}: {e}")
    found_init = any(str(x).endswith("_init.py") for x in modules_subdir.rglob("*"))
    found_exec = any(str(x).endswith("_execute.py") for x in modules_subdir.rglob("*"))
    found_cleanup = any(str(x).endswith("_cleanup.py") for x in modules_subdir.rglob("*"))
    if not (found_init and found_exec and found_cleanup):
        issues.append("Missing one of init/execute/cleanup files in candidate")
    ok = len(issues) == 0
    audit_log({"action": "inspect", "candidate": str(candidate_path), "ok": ok, "issue_count": len(issues)})
    return {"ok": ok, "issues": issues, "files_checked": files_checked}

# Tester: use containerless sandbox runner
def tester_adapter(candidate_path: str, manifest_entry: Dict[str, Any], test_inputs: List[Dict[str, Any]]) -> Dict[str, Any]:
    modules_dir = Path(candidate_path) / "modules"
    if not modules_dir.exists():
        return {"ok": False, "error": "modules_dir_missing"}
    exec_files = list(modules_dir.rglob("*_execute.py"))
    if not exec_files:
        return {"ok": False, "error": "no_execute_files_found"}
    exec_rel = str(exec_files[0].relative_to(modules_dir))
    results = []
    ok_all = True
    for inp in test_inputs:
        inp_json = json.dumps(inp)
        resource_limits = {"mem_mb": SANDBOX_MEM_MB, "cpu_seconds": SANDBOX_CPU_SECONDS, "nofile": SANDBOX_NOFILE}
        res = sandbox_runner.run_module_candidate(Path(candidate_path), exec_rel, inp_json, resource_limits, timeout_s=SANDBOX_TIMEOUT_SEC, use_cgroups_if_available=True)
        results.append(res)
        if not res.get("ok"):
            ok_all = False
            break
    audit_log({"action": "sandbox_test", "candidate": str(candidate_path), "ok": ok_all, "tests_run": len(results)})
    return {"ok": ok_all, "results": results}

# Snapshot & restore (git)
def snapshot_adapter(module_id: str) -> Optional[str]:
    try:
        reg = read_registry()
        meta = (reg.get("modules", {}) or {}).get(module_id) or {}
        files = meta.get("files", [])
        if not files:
            subprocess.check_call(["git", "add", str(MODULES_DIR)], cwd=str(REPO_ROOT))
        else:
            for rel in files:
                abs_path = (MODULES_DIR / rel).resolve()
                if abs_path.exists():
                    subprocess.check_call(["git", "add", str(abs_path)], cwd=str(REPO_ROOT))
        msg = f"autonomy snapshot {module_id} at {datetime.utcnow().isoformat()}Z"
        subprocess.check_call(["git", "commit", "-m", msg], cwd=str(REPO_ROOT))
        out = subprocess.check_output(["git", "rev-parse", "HEAD"], cwd=str(REPO_ROOT))
        commit = out.decode().strip()
        audit_log({"action": "snapshot", "module_id": module_id, "commit": commit})
        return commit
    except subprocess.CalledProcessError:
        try:
            out = subprocess.check_output(["git", "rev-parse", "HEAD"], cwd=str(REPO_ROOT))
            commit = out.decode().strip()
            return commit
        except Exception:
            logger.exception("Snapshot failed")
            return None

def restore_snapshot_adapter(commit_hash: str) -> Dict[str, Any]:
    try:
        subprocess.check_call(["git", "reset", "--hard", commit_hash], cwd=str(REPO_ROOT))
        audit_log({"action": "restore_snapshot", "commit": commit_hash})
        return {"ok": True}
    except subprocess.CalledProcessError:
        logger.exception("Restore snapshot failed for %s", commit_hash)
        return {"ok": False, "error": "git_reset_failed"}

# Sign artifact (SHA256 over files)
def sign_adapter(path_like: str, metadata: Dict[str, Any]) -> str:
    import hashlib
    h = hashlib.sha256()
    p = Path(path_like)
    if p.is_file():
        h.update(p.read_bytes())
    else:
        for f in sorted([x for x in p.rglob("*") if x.is_file()]):
            rel = str(f.relative_to(p)).encode("utf-8")
            h.update(rel); h.update(f.read_bytes())
    sig = h.hexdigest()
    audit_log({"action": "sign", "path": str(path_like), "signature": sig})
    return sig

# Promote adapter: move candidate into modules dir and atomically update registry via etcd
def promote_adapter(candidate_path: str, manifest_entry: Dict[str, Any]) -> Dict[str, Any]:
    module_id = str(manifest_entry.get("id"))
    lock_name = f"promote-{module_id}"
    try:
        with etcd_store.acquire_lock(lock_name, ttl=60):
            cand = Path(candidate_path)
            modules_sub = cand / "modules"
            if not modules_sub.exists():
                return {"ok": False, "error": "candidate_modules_missing"}
            category = manifest_entry.get("category", "processor")
            target_dir = MODULES_DIR / category
            target_dir.mkdir(parents=True, exist_ok=True)
            moved = []
            # move each file (atomic replace)
            for f in modules_sub.iterdir():
                dest = target_dir / f.name
                if dest.exists():
                    bak = target_dir / f"{f.name}.bak.{int(time.time())}"
                    shutil.move(str(dest), str(bak))
                os.replace(str(f), str(dest))
                moved.append(str(dest.relative_to(MODULES_DIR)))
            # update registry via etcd atomic updater
            def updater(curr):
                if "modules" not in curr:
                    curr["modules"] = {}
                curr["modules"][module_id] = {
                    "id": module_id,
                    "name": manifest_entry.get("name"),
                    "category": category,
                    "files": moved,
                    "manifest": manifest_entry
                }
                return curr
            atomic_registry_update(updater)
            signature = sign_adapter(str(target_dir), {"module_id": module_id})
            artifact = {"module_id": module_id, "files": moved, "signature": signature, "promoted_at": datetime.utcnow().isoformat() + "Z"}
            audit_log({"action": "promote", "module_id": module_id, "artifact": artifact})
            return {"ok": True, "artifact": artifact}
    except Exception as e:
        logger.exception("Promotion failed: %s", e)
        return {"ok": False, "error": "promotion_exception", "details": str(e)}

# Human notify
def notify_adapter(payload: Dict[str, Any]) -> str:
    corr = uuid.uuid4().hex
    out = APPROVALS_DIR / f"approval_{corr}.json"
    out.write_text(json.dumps(payload, indent=2), encoding="utf-8")
    audit_log({"action": "notify_human", "correlation": corr, "summary": payload.get("incident", {}).get("module_id")})
    return corr

# Wire into AutonomyManager
def build_prod_autonomy_manager(autonomy_level: str = "balanced", hybrid_mode: bool = True, protected_scopes: Optional[List[str]] = None) -> AutonomyManager:
    reg = read_registry()
    manifest_registry = {}
    modules = reg.get("modules", {}) or {}
    for mid, meta in modules.items():
        manifest_registry[mid] = meta.get("manifest") or meta
    mgr = AutonomyManager(
        manifest_registry=manifest_registry,
        autonomy_level=autonomy_level,
        hybrid_mode=hybrid_mode,
        protected_scopes=protected_scopes or [],
        generator_func=generator_adapter,
        inspector_func=inspector_adapter,
        sandbox_tester=tester_adapter,
        promote_func=promote_adapter,
        snapshot_func=snapshot_adapter,
        restore_snapshot=restore_snapshot_adapter,
        notify_human=notify_adapter,
        sign_artifact=sign_adapter,
        max_repair_attempts=int(os.environ.get("AUTONOMY_MAX_ATTEMPTS", "3")),
        worker_pool=WORKER_POOL,
    )
    logger.info("Built prod AutonomyManager (level=%s hybrid=%s)", autonomy_level, hybrid_mode)
    return mgr

# CLI / function entrypoint
def handle_incident_and_return(incident_payload: Dict[str, Any], autonomy_level: str = "balanced") -> Dict[str, Any]:
    mgr = build_prod_autonomy_manager(autonomy_level=autonomy_level)
    incident = Incident(
        module_id=incident_payload.get("module_id"),
        error=incident_payload.get("error", ""),
        stacktrace=incident_payload.get("stacktrace", ""),
        metrics=incident_payload.get("metrics", {}),
        extra=incident_payload.get("extra", {}),
    )
    res: RepairResult = mgr.handle_incident(incident)
    audit_log({"action": "incident_handled", "module_id": incident.module_id, "result": res.__dict__})
    return {"success": res.success, "promoted": res.promoted, "attempts": res.attempts, "details": res.details}

# Safe CLI invocation
if __name__ == "__main__":
    raw = sys.stdin.read()
    try:
        payload = json.loads(raw) if raw else {}
    except Exception:
        print("Provide JSON incident on stdin", file=sys.stderr); sys.exit(2)
    out = handle_incident_and_return(payload, autonomy_level=payload.get("autonomy_level", "balanced"))
    print(json.dumps(out, indent=2))
```

---

# What I changed compared to the template-based version

* Removed any Docker/socket/volume expectations.
* Removed Helm/systemd template references.
* Uses `sandbox_runner_no_docker` for universal portability.
* Keeps etcd-based registry/locking for multi-node coordination (etcd itself is optional — etcd_store falls back to a file if not available).
* Short, single-file integration so you can embed it in Aurora's own runtime.

---

# Next steps I can do right away (pick 1–2)

**a.** Patch your bundle: automatically replace `prod_autonomy.py` imports to use `sandbox_runner_no_docker` and add this `prod_autonomy_nontemplated.py` into the bundle (I will output the exact repo diff).
**b.** Generate `tests/test_sandbox_no_docker.py` that runs the sandbox runner against 3 generated modules and asserts it enforces memory/time limits.
**c.** Provide a tiny HTTP wrapper file (FastAPI) that calls `handle_incident_and_return()` but with no templates / no k8s assumptions (just one file you can run with `uvicorn`).

Which would you like first? **(a / b / c)**
