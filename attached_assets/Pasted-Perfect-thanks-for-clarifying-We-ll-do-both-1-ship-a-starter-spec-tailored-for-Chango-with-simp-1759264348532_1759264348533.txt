Perfect—thanks for clarifying. We’ll do both:
	1.	ship a starter spec tailored for Chango (with simple I/O adapter so your other program can feed tasks into Aurora), and
	2.	wire in T02 persistent corpus hooks (JSONL + SQLite) so Aurora starts “learning” from every run immediately.

Below are copy-paste files/patches, in order.

⸻

1) Starter spec for Chango + I/O adapter

specs/chango_spec.md

# AURORA SPEC (Chango starter)
# Purpose: small but representative base for Chango integrations:
# - text utilities
# - numeric helpers
# - safe guards and cross-calls
#
# Functions express examples, pre/post, and invariants where useful.

functions:
  - name: normalize_spaces
    args: s:str
    returns: str
    examples:
      - normalize_spaces("  hello   world ") = "hello world"
      - normalize_spaces("a   b") = "a b"
      - normalize_spaces("") = ""
    post:
      - "ret.strip() == ret"
      - "'  ' not in ret"

  - name: tokenize
    args: s:str
    returns: list[str]
    examples:
      - tokenize("hello world") = ["hello","world"]
      - tokenize("  spaced   out ") = ["spaced","out"]
      - tokenize("") = []
    post:
      - "all(len(x) > 0 for x in ret)"

  - name: safe_int
    args: s:str, default:int
    returns: int
    examples:
      - safe_int("42", 0) = 42
      - safe_int("x", 5) = 5
      - safe_int("", -1) = -1
    post:
      - "isinstance(ret, int)"

  - name: clamp
    args: x:int, lo:int, hi:int
    returns: int
    examples:
      - clamp(5, 0, 10) = 5
      - clamp(-3, 0, 10) = 0
      - clamp(15, 0, 10) = 10
    pre: lo <= hi
    post:
      - "lo <= ret <= hi"

  - name: score_keyword
    args: s:str, kw:str
    returns: int
    examples:
      - score_keyword("I love apples", "apple") = 1
      - score_keyword("apple apple", "apple") = 2
      - score_keyword("", "x") = 0
    post:
      - "ret >= 0"

  - name: intent_score
    args: s:str, intents:list[str]
    returns: int
    examples:
      - intent_score("buy shoes now", ["buy","sell"]) = 1
      - intent_score("sell sell", ["buy","sell"]) = 2
      - intent_score("", ["a"]) = 0
    post:
      - "ret >= 0"

  - name: assemble_reply
    args: tokens:list[str]
    returns: str
    examples:
      - assemble_reply(["hi","there"]) = "hi there"
      - assemble_reply([]) = ""
    post:
      - "ret == ' '.join(tokens)"

aurora_x/adapters/chango_io.py

from __future__ import annotations
from dataclasses import dataclass
from pathlib import Path
from typing import List, Dict, Any

@dataclass
class ChangoTask:
    name: str                 # function name
    args: List[str]           # e.g. ["s:str", "kw:str"]
    returns: str              # e.g. "int"
    examples: List[str]       # e.g. ["foo(1)=2"]
    pre: List[str] | None = None
    post: List[str] | None = None
    invariants: List[str] | None = None

def to_spec_md(tasks: List[ChangoTask]) -> str:
    lines = ["# AURORA SPEC (from Chango)", "functions:"]
    for t in tasks:
        lines += [f"  - name: {t.name}",
                  f"    args: {', '.join(t.args)}",
                  f"    returns: {t.returns}",
                  "    examples:"]
        for ex in t.examples:
            lines.append(f"      - {ex}")
        if t.invariants:
            lines.append("    invariants:")
            for inv in t.invariants: lines.append(f"      - {inv}")
        if t.pre:
            for p in t.pre: lines.append(f"    pre: {p}")
        if t.post:
            lines.append("    post:")
            for p in t.post: lines.append(f"      - {p}")
        lines.append("")  # spacer
    return "\n".join(lines)

def save_spec_md(path: str | Path, md: str) -> None:
    p = Path(path); p.parent.mkdir(parents=True, exist_ok=True); p.write_text(md, encoding="utf-8")

How Chango uses it (example):

# from your integration
from aurora_x.adapters.chango_io import ChangoTask, to_spec_md, save_spec_md

tasks = [
    ChangoTask("normalize_spaces", ["s:str"], "str",
               ['normalize_spaces("  hi  ") = "hi"'],
               post=['"  " not in ret']),
    # add more dynamically...
]
md = to_spec_md(tasks)
save_spec_md("./specs/from_chango.md", md)
# then run: aurorax --spec-file ./specs/from_chango.md --outdir runs


⸻

2) Persistent Corpus (JSONL + SQLite) hooks

aurora_x/corpus.py

from __future__ import annotations
import json, sqlite3, time, hashlib
from pathlib import Path
from typing import Any, Dict

def _ts() -> str: return time.strftime("%Y-%m-%d %H:%M:%S", time.localtime())

def spec_id_for_text(spec_text: str) -> str:
    return hashlib.sha256(spec_text.encode("utf-8")).hexdigest()[:16]

def append_jsonl(path: Path, rec: Dict[str, Any]) -> None:
    path.parent.mkdir(parents=True, exist_ok=True)
    with path.open("a", encoding="utf-8") as f:
        f.write(json.dumps(rec, ensure_ascii=False) + "\n")

def ensure_sqlite(db_path: Path) -> sqlite3.Connection:
    db_path.parent.mkdir(parents=True, exist_ok=True)
    conn = sqlite3.connect(str(db_path))
    conn.execute("""
        CREATE TABLE IF NOT EXISTS corpus(
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            ts TEXT,
            spec_id TEXT,
            spec_hash TEXT,
            func_name TEXT,
            passed INT,
            total INT,
            score REAL,
            failing TEXT,
            snippet TEXT
        )
    """)
    conn.execute("CREATE INDEX IF NOT EXISTS idx_corpus_spec_fn ON corpus(spec_id, func_name)")
    return conn

def insert_sqlite(conn: sqlite3.Connection, rec: Dict[str, Any]) -> None:
    conn.execute("""INSERT INTO corpus(ts,spec_id,spec_hash,func_name,passed,total,score,failing,snippet)
                    VALUES(?,?,?,?,?,?,?,?,?)""",
                 (rec["ts"],rec["spec_id"],rec["spec_hash"],rec["func_name"],
                  rec["passed"],rec["total"],rec["score"],rec.get("failing",""),rec["snippet"]))
    conn.commit()

def record(outdir: Path, spec_text: str, func_name: str,
           passed: int, total: int, score: float, snippet: str, failing: str = "") -> None:
    sid = spec_id_for_text(spec_text)
    base = {"ts": _ts(), "spec_id": sid, "spec_hash": sid, "func_name": func_name,
            "passed": passed, "total": total, "score": score, "failing": failing, "snippet": snippet}
    append_jsonl(outdir / "corpus.jsonl", base)
    conn = ensure_sqlite(outdir / "corpus.db")
    insert_sqlite(conn, base)

Patch aurora_x/main.py (add imports + two small hooks)
	1.	Imports (top of file):

# add:
from .corpus import record as corpus_record, spec_id_for_text

	2.	Store spec_id when run begins (inside AuroraX.run after spec = parse_spec(spec_text)):

sid = spec_id_for_text(spec_text)

	3.	Hook after choosing best candidate (inside synthesize_best return path or immediately after calling it in run()).
Simplest: in run(), right after computing best_map[f.name]:

cand = self.synthesize_best(f, callees_meta, base_prefix=prefix)
best_map[f.name] = cand.src
# record initial candidate quality
p, t, sc = run_examples_with_post((prefix + "\n\n" + cand.src + "\n"), f.name,
                                  [a for a,_ in f.args], f.examples, f.post)
corpus_record(self.repo.root, spec_text, f.name, p, t, sc, cand.src)

	4.	Hook each iteration (after export_graph_and_scores, we already loop functions — record their current scores):

Inside export_graph_and_scores, after computing p,t,sc, add:

# also persist to corpus store
try:
    module_src = module_src  # already in scope of export
except NameError:
    module_src = ""
corpus_record(self.repo.root, read_file(self.repo.path("run_config.json")), f.name, p, t, sc, "<snapshot>")

If you prefer not to write in export_graph_and_scores, you can keep the first hook only. It’s already enough to begin accumulating a useful corpus.

(If you want me to paste a ready-to-drop main.py with these changes inlined, say the word and I’ll post the entire file.)

⸻

3) README additions (how to use)

Append to README.md:

## Chango integration
- Build a spec programmatically:
  ```python
  from aurora_x.adapters.chango_io import ChangoTask, to_spec_md, save_spec_md
  tasks = [ChangoTask("normalize_spaces", ["s:str"], "str", ['normalize_spaces("  hi  ") = "hi"'])]
  md = to_spec_md(tasks); save_spec_md("./specs/from_chango.md", md)

	•	Run:

aurorax --spec-file ./specs/from_chango.md --outdir runs



Persistent corpus

Aurora writes run artifacts to:
	•	runs/corpus.jsonl (append-only history)
	•	runs/corpus.db (SQLite, indexed)

Query example:

sqlite3 runs/corpus.db "SELECT func_name, MAX(passed) as maxp, MIN(score) as best FROM corpus GROUP BY func_name;"

---

# 4) Makefile (optional tiny helper)
Add a helper to inspect the corpus:
```make
corpus-top:
	@echo "Top snapshots per function"; \
	sqlite3 $(OUTDIR)/corpus.db "SELECT func_name, MAX(passed) as maxp, MIN(score) as best FROM corpus GROUP BY func_name;"


⸻

What this gives you now
	•	Chango can emit tasks → spec with a tiny adapter.
	•	Aurora persists every function candidate/score to a growing corpus (JSONL + SQLite).
	•	Future work (T02.2+) can seed synthesis from the best prior snippets for similar signatures/specs.

Want me to:
	•	paste a fully merged main.py with the corpus hooks included, or
	•	proceed to the “use corpus during synthesis” step (re-seed candidates with past winners), or
	•	both?