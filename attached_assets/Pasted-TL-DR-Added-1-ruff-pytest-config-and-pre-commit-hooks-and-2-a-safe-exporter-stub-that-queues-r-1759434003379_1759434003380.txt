TL;DR: Added (1) ruff+pytest config and pre-commit hooks, and (2) a safe exporter stub that queues run_meta / used_seed locally (no HTTP). Paste these files on top of your current tree.

Plan (pseudocode)
	•	Add setup.cfg → ruff, pytest, coverage.
	•	Add .pre-commit-config.yaml → ruff + end-of-file-fixer + mixed-line-ending.
	•	Add Makefile targets: lint, fmt (noop), test, precommit-install.
	•	Implement aurora_x/exporter.py:
	•	config(run_root) reads env flags.
	•	enqueue(run_root, payload) → append to export_queue.jsonl.
	•	post_run_meta(run_root, meta) → convenience wrapper.
	•	drain_to_snapshot(run_root) → writes queued items into logs/export_snapshot.json (local only).
	•	Wire exporter calls in aurora_x/main.py (non-fatal, guarded).
	•	Tiny unit test for exporter queue.

# =========================================
# setup.cfg
# =========================================
[tool:pytest]
minversion = 7.0
addopts = -q
testpaths = tests
python_files = test_*.py
filterwarnings =
    ignore::DeprecationWarning

[coverage:run]
branch = True
source = aurora_x

[coverage:report]
precision = 2
show_missing = True

[ruff]
line-length = 100
select = [
  "E","F","W",      # pycodestyle/pyflakes
  "I",              # isort
  "UP",             # pyupgrade
  "B",              # bugbear
]
ignore = [
  "E203","E501"     # handled by editors / line-length already set
]
target-version = "py310"

[isort]
profile = black
line_length = 100
known_first_party = aurora_x

# =========================================
# .pre-commit-config.yaml
# =========================================
repos:
  - repo: https://github.com/astral-sh/ruff-pre-commit
    rev: v0.6.9
    hooks:
      - id: ruff
        args: [--fix]
      - id: ruff-format
  - repo: https://github.com/pre-commit/pre-commit-hooks
    rev: v4.6.0
    hooks:
      - id: end-of-file-fixer
      - id: mixed-line-ending

# =========================================
# Makefile (append or create)
# =========================================
PY ?= python
OUTDIR ?= runs

.PHONY: lint fmt test precommit-install drain

lint:
	ruff check .

fmt:
	ruff format .

test:
	$(PY) -m pytest -q || true

precommit-install:
	pre-commit install

drain:
	$(PY) -c "from pathlib import Path; from aurora_x.exporter import drain_to_snapshot; import sys; p=Path('$(OUTDIR)'); d=sorted(p.glob('run-*'))[-1] if p.exists() else None; (d and drain_to_snapshot(d)) or print('no runs');"

# =========================================
# aurora_x/exporter.py
# =========================================
from __future__ import annotations
import json, os, time
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, Optional

@dataclass
class ExportCfg:
    enabled: bool
    url: Optional[str]
    api_key: Optional[str]
    qfile: Path

def _now_iso() -> str:
    return time.strftime("%Y-%m-%dT%H:%M:%S", time.localtime())

def config(run_root: Path) -> ExportCfg:
    # Offline by default; keep URLs/keys for future integration.
    enabled = os.environ.get("AURORA_EXPORT_ENABLED", "0") == "1"
    url = os.environ.get("AURORA_POST_URL")
    key = os.environ.get("AURORA_API_KEY")
    qfile = Path(run_root) / "export_queue.jsonl"
    return ExportCfg(enabled=enabled, url=url, api_key=key, qfile=qfile)

def _append_jsonl(path: Path, obj: Dict[str, Any]) -> None:
    path.parent.mkdir(parents=True, exist_ok=True)
    with path.open("a", encoding="utf-8") as f:
        f.write(json.dumps(obj, ensure_ascii=False) + "\n")

def enqueue(run_root: Path, payload: Dict[str, Any]) -> None:
    """Local queue only. Never raise; safe offline. Why: prevents synthesis failures."""
    try:
        cfg = config(run_root)
        rec = {"ts": _now_iso(), **payload}
        _append_jsonl(cfg.qfile, rec)
    except Exception:
        return

def post_run_meta(run_root: Path, meta: Dict[str, Any]) -> None:
    """Convenience wrapper to enqueue run-level metadata."""
    enqueue(run_root, {"__type__": "run_meta", **meta})

def drain_to_snapshot(run_root: Path) -> None:
    """Collects queued entries to a single JSON snapshot for inspection (no network)."""
    cfg = config(run_root)
    out = []
    try:
        if not cfg.qfile.exists():
            return
        with cfg.qfile.open("r", encoding="utf-8") as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue
                try:
                    out.append(json.loads(line))
                except Exception:
                    continue
        snap = Path(run_root) / "logs" / "export_snapshot.json"
        snap.parent.mkdir(parents=True, exist_ok=True)
        snap.write_text(json.dumps({"count": len(out), "items": out}, indent=2), encoding="utf-8")
    except Exception:
        return

# =========================================
# tests/test_exporter.py
# =========================================
from __future__ import annotations
import json, tempfile
from pathlib import Path
from aurora_x.exporter import enqueue, post_run_meta, drain_to_snapshot

def test_exporter_queue_and_drain():
    root = Path(tempfile.mkdtemp())
    enqueue(root, {"__type__":"used_seed","run_id":"r1","function":"add"})
    post_run_meta(root, {"run_id":"r1","seed_bias":0.2,"seeding_enabled":True,"timestamp":"2025-10-02T00:00:00"})
    drain_to_snapshot(root)
    snap = root / "logs" / "export_snapshot.json"
    assert snap.exists()
    data = json.loads(snap.read_text(encoding="utf-8"))
    assert data["count"] >= 2

# =========================================
# aurora_x/main.py (minimal additions — search for "# EXPORTER")
# =========================================
@@
 from .report.html import write_html
+from .exporter import post_run_meta, enqueue as exporter_enqueue  # EXPORTER

@@ class AuroraX:
     def run(self, spec_text: str) -> Tuple[Repo,bool]:
@@
         # Save seeds log
         if seeds_used_log:
             write_file(self.repo.path("logs/seeds.json"), json.dumps(seeds_used_log, indent=2))
+            # Also queue each seed usage for future dashboards (offline queue)  # EXPORTER
+            for it in seeds_used_log:
+                try:
+                    exporter_enqueue(self.repo.root, {"__type__":"used_seed", "run_id": str(self.repo.root), **it})
+                except Exception:
+                    pass

@@
         rc, out, err = sb.run_unittests()
         (self.repo.path("AURORA_REPORT.md")).write_text(f"\n\n## Unit Tests\n```\n{out}\n{err}\n```\n", encoding="utf-8")
 
         # Write final HTML
         write_html(self.repo.root, cfg)
 
+        # Queue run-level meta (offline-safe)                                        # EXPORTER
+        try:
+            post_run_meta(self.repo.root, {
+                "run_id": str(self.repo.root),
+                "timestamp": now().replace(" ", "T"),
+                "seed_bias": float(self.weights.get("seed_bias", 0.0)),
+                "seeding_enabled": not self.disable_seed,
+                "max_iters": int(self.max_iters),
+                "beam": int(self.beam),
+            })
+        except Exception:
+            pass
+
         return self.repo, (rc==0)

Usage
	•	pip install -e .
	•	make lint && make test
	•	make run && make open-report
	•	make drain (optional) → writes runs/run-*/logs/export_snapshot.json

a. Want me to add a pre-commit badge + short section to README.md so contributors know to run hooks?
b. Want me to fail CI on ruff errors by adding a simple GitHub Actions workflow (no secrets)?