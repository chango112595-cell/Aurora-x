TL;DR: I reviewed Replit’s schema, locked decisions, and wired the corpus to match—UUID ids, ISO8601 timestamps, JSON arrays for failing tests & calls, signature+post similarity, indexes, and safe DB migrations. Below: short plan, then drop-in code (replace the previous aurora_x/corpus.py and aurora_x/main.py).

Plan (pseudocode)
	•	Adopt Replit’s fields; mark required vs optional.
	•	Store arrays as JSON TEXT columns.
	•	Use ISO 8601 UTC timestamps.
	•	Compute: func_signature, complexity (AST size of function), calls_functions (static call scan).
	•	Record iteration, duration_ms, synthesis_method="ast_beam".
	•	Add indexes: (spec_id, func_name), (func_name, passed=total DESC, score ASC), (timestamp DESC), (sig_key).
	•	Keep prior similarity retrieval working.

Final code (copy-paste)

# =========================================
# aurora_x/corpus.py
# =========================================
from __future__ import annotations
import json, sqlite3, hashlib, re, uuid
from datetime import datetime, timezone
from pathlib import Path
from typing import Any, Dict, List, Tuple, Optional

# ---------- time/hash ----------
def iso_utc_now() -> str:
    # ISO 8601 Zulu
    return datetime.now(timezone.utc).isoformat().replace("+00:00", "Z")

def spec_id_for_text(spec_text: str) -> str:
    full = hashlib.sha256(spec_text.encode("utf-8")).hexdigest()
    return full[:12], full  # (short, full)

# ---------- BOW helpers ----------
_WORD = re.compile(r"[A-Za-z_][A-Za-z0-9_]*")
def bow_tokens(s: str) -> List[str]:
    toks = [t.lower() for t in _WORD.findall(s or "")]
    return [t for t in toks if t not in {"and","or","not","ret","true","false","none"}]

def jaccard(a: List[str], b: List[str]) -> float:
    sa, sb = set(a), set(b)
    if not sa and not sb: return 0.0
    return len(sa & sb) / max(1, len(sa | sb))

# ---------- SQLite ----------
def ensure_sqlite(db_path: Path) -> sqlite3.Connection:
    db_path.parent.mkdir(parents=True, exist_ok=True)
    conn = sqlite3.connect(str(db_path))
    conn.execute("""
        CREATE TABLE IF NOT EXISTS corpus(
            id TEXT PRIMARY KEY,                -- UUID
            timestamp TEXT,                     -- ISO8601 Z
            spec_id TEXT,                       -- short
            spec_hash TEXT,                     -- full
            func_name TEXT,
            func_signature TEXT,
            passed INT,
            total INT,
            score REAL,
            failing_tests TEXT,                 -- JSON array
            snippet TEXT,
            complexity INT,
            iteration INT,
            calls_functions TEXT,               -- JSON array
            sig_key TEXT,                       -- name|argtypes|return
            post_bow TEXT,                      -- space-joined tokens
            duration_ms INT,
            synthesis_method TEXT               -- "ast_beam", etc.
        )
    """)
    # Legacy migrations (ignore if already there)
    def _add(col: str, ddl: str):
        try: conn.execute(ddl)
        except sqlite3.OperationalError: pass

    _add("func_signature", "ALTER TABLE corpus ADD COLUMN func_signature TEXT")
    _add("failing_tests", "ALTER TABLE corpus ADD COLUMN failing_tests TEXT")
    _add("complexity", "ALTER TABLE corpus ADD COLUMN complexity INT")
    _add("iteration", "ALTER TABLE corpus ADD COLUMN iteration INT")
    _add("calls_functions", "ALTER TABLE corpus ADD COLUMN calls_functions TEXT")
    _add("sig_key", "ALTER TABLE corpus ADD COLUMN sig_key TEXT")
    _add("post_bow", "ALTER TABLE corpus ADD COLUMN post_bow TEXT")
    _add("duration_ms", "ALTER TABLE corpus ADD COLUMN duration_ms INT")
    _add("synthesis_method", "ALTER TABLE corpus ADD COLUMN synthesis_method TEXT")

    # Indexes
    conn.execute("CREATE INDEX IF NOT EXISTS idx_spec_fn ON corpus(spec_id, func_name)")
    conn.execute("CREATE INDEX IF NOT EXISTS idx_sigkey ON corpus(sig_key)")
    conn.execute("CREATE INDEX IF NOT EXISTS idx_time ON corpus(timestamp)")  # DESC used at query-time
    conn.execute("""
        CREATE INDEX IF NOT EXISTS idx_best_fn 
        ON corpus(func_name, score, passed, total)
    """)
    return conn

# ---------- Recording ----------
def _json(v: Any) -> str:
    return json.dumps(v, ensure_ascii=False)

def record(
    outdir: Path,
    *,
    spec_text: str,
    func_name: str,
    func_signature: str,
    snippet: str,
    passed: int,
    total: int,
    score: float,
    iteration: Optional[int] = None,
    failing_tests: Optional[List[str]] = None,
    complexity: Optional[int] = None,
    calls_functions: Optional[List[str]] = None,
    sig_key: str = "",
    post_bow: List[str] | None = None,
    duration_ms: Optional[int] = None,
    synthesis_method: str = "ast_beam",
) -> None:
    sid_short, sid_full = spec_id_for_text(spec_text)
    rec = {
        "id": str(uuid.uuid4()),
        "timestamp": iso_utc_now(),
        "spec_id": sid_short,
        "spec_hash": sid_full,
        "func_name": func_name,
        "func_signature": func_signature,
        "passed": int(passed),
        "total": int(total),
        "score": float(score),
        "failing_tests": _json(failing_tests or []),
        "snippet": snippet,
        "complexity": complexity if complexity is not None else -1,
        "iteration": iteration if iteration is not None else -1,
        "calls_functions": _json(calls_functions or []),
        "sig_key": sig_key,
        "post_bow": " ".join(post_bow or []),
        "duration_ms": duration_ms if duration_ms is not None else 0,
        "synthesis_method": synthesis_method,
    }

    # Write JSONL for quick tailing
    jsonl_path = outdir / "corpus.jsonl"
    jsonl_path.parent.mkdir(parents=True, exist_ok=True)
    with jsonl_path.open("a", encoding="utf-8") as f:
        f.write(json.dumps(rec, ensure_ascii=False) + "\n")

    # Write SQLite for retrieval
    conn = ensure_sqlite(outdir / "corpus.db")
    conn.execute(
        """INSERT INTO corpus(
           id, timestamp, spec_id, spec_hash, func_name, func_signature,
           passed, total, score, failing_tests, snippet, complexity, iteration,
           calls_functions, sig_key, post_bow, duration_ms, synthesis_method
        ) VALUES (?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?)""",
        (
            rec["id"], rec["timestamp"], rec["spec_id"], rec["spec_hash"],
            rec["func_name"], rec["func_signature"], rec["passed"], rec["total"],
            rec["score"], rec["failing_tests"], rec["snippet"], rec["complexity"],
            rec["iteration"], rec["calls_functions"], rec["sig_key"], rec["post_bow"],
            rec["duration_ms"], rec["synthesis_method"]
        )
    )
    conn.commit()
    conn.close()

# ---------- Retrieval ----------
def top_snippets(db_path: Path, func_name: str, limit: int = 5) -> List[str]:
    if not db_path.exists(): return []
    conn = sqlite3.connect(str(db_path))
    try:
        cur = conn.execute(
            """SELECT snippet, passed, total, score, timestamp
               FROM corpus
               WHERE func_name = ?
               ORDER BY (passed = total) DESC, score ASC, timestamp DESC
               LIMIT ?""",
            (func_name, limit)
        )
        rows = cur.fetchall()
    finally:
        conn.close()
    seen, out = set(), []
    for snip, *_ in rows:
        if snip and snip not in seen:
            seen.add(snip); out.append(snip)
    return out

def top_snippets_similar(
    db_path: Path,
    target_sig_key: str,
    target_post_bow: List[str],
    limit: int = 5
) -> List[str]:
    if not db_path.exists(): return []
    conn = sqlite3.connect(str(db_path))
    try:
        cur = conn.execute("""SELECT snippet, sig_key, post_bow, passed, total, score, timestamp
                              FROM corpus ORDER BY timestamp DESC LIMIT 2000""")
        rows = cur.fetchall()
    finally:
        conn.close()

    out: List[Tuple[float,str]] = []
    try:
        t_name, t_args, t_ret = target_sig_key.split("|", 2)
    except Exception:
        t_name, t_args, t_ret = "", "", ""
    for snip, sig_key, post_bow, passed, total, score, ts in rows:
        if not snip: continue
        try:
            name, args, ret = (sig_key or "||").split("|", 2)
        except Exception:
            name, args, ret = "", "", ""
        same_ret = 1.0 if ret == t_ret and ret != "" else 0.0
        arg_match = 1.0 if args == t_args and args != "" else 0.0
        bow = bow_tokens(post_bow or "")
        jac = jaccard(bow, target_post_bow)
        sim = 0.5* same_ret + 0.3* arg_match + 0.2* jac
        if passed == total: sim += 0.15
        out.append((sim, snip))
    out.sort(key=lambda x: x[0], reverse=True)
    seen, res = set(), []
    for sim, snip in out:
        if snip not in seen:
            seen.add(snip); res.append(snip)
        if len(res) >= limit: break
    return res

# =========================================
# aurora_x/main.py  (updated to feed new corpus fields)
# =========================================
from __future__ import annotations
import argparse, ast, hashlib, json, math, os, random, re, signal, subprocess, sys, tempfile, textwrap, threading, time
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, Iterable, List, Optional, Tuple

from .corpus import (
    record as corpus_record,
    top_snippets, top_snippets_similar,
    bow_tokens,
)

# ---------- Utils ----------
def now() -> str: return time.strftime("%Y-%m-%d %H:%M:%S", time.localtime())
def ts_slug() -> str: return time.strftime("%Y%m%d-%H%M%S", time.localtime())
def read_file(p: Path) -> str: return p.read_text(encoding="utf-8")
def write_file(p: Path, s: str) -> None: p.parent.mkdir(parents=True, exist_ok=True); p.write_text(s, encoding="utf-8")
def sha256_str(s: str) -> str: return hashlib.sha256(s.encode("utf-8")).hexdigest()
def jsonl_append(p: Path, obj: Dict[str, Any]) -> None:
    p.parent.mkdir(parents=True, exist_ok=True)
    with p.open("a", encoding="utf-8") as f: f.write(json.dumps(obj, ensure_ascii=False) + "\n")

# ---------- Repo ----------
@dataclass
class Repo:
    root: Path
    hashes: Dict[str, str]
    @classmethod
    def create(cls, outdir: Optional[Path]) -> "Repo":
        if outdir:
            run_root = outdir / f"run-{ts_slug()}"
            (run_root / "src").mkdir(parents=True, exist_ok=True)
            (run_root / "tests").mkdir(parents=True, exist_ok=True)
            (run_root / "logs").mkdir(parents=True, exist_ok=True)
            write_file(run_root / "AURORA_PLAN.md", "# Plan\n")
            write_file(run_root / "AURORA_REPORT.md", "# Report\n")
            return cls(run_root, {})
        root = Path(tempfile.mkdtemp(prefix="aurora_x_repo_"))
        (root / "src").mkdir(parents=True, exist_ok=True)
        (root / "tests").mkdir(parents=True, exist_ok=True)
        (root / "logs").mkdir(parents=True, exist_ok=True)
        write_file(root / "AURORA_PLAN.md", "# Plan\n")
        write_file(root / "AURORA_REPORT.md", "# Report\n")
        return cls(root, {})
    def path(self, rel: str) -> Path: return self.root / rel
    def list_files(self) -> List[str]:
        return sorted(str(p.relative_to(self.root)) for p in self.root.rglob("*") if p.is_file())
    def set_hash(self, rel: str, content: str) -> None: self.hashes[rel] = sha256_str(content)

# ---------- Spec ----------
@dataclass
class FunctionSpec:
    name: str
    args: List[Tuple[str, str]]
    returns: str
    examples: List[Tuple[List[Any], Any]]
    invariants: List[str]
    pre: List[str]
    post: List[str]

@dataclass
class Spec:
    functions: List[FunctionSpec]

_EX_LINE = re.compile(r"^\s*([a-zA-Z_][a-zA-Z0-9_]*)\((.*)\)\s*=\s*(.+?)\s*$")

def _split_args(s: str) -> List[str]:
    parts, cur, depth, in_str, quote = [], "", 0, False, ""
    for ch in s:
        if in_str: cur += ch
        if in_str and ch == quote: in_str = False; continue
        if not in_str and ch in ("'", '"'): in_str, quote = True, ch; cur += ch; continue
        if ch in "([{": depth += 1
        elif ch in ")]}": depth -= 1
        if ch == "," and depth == 0: parts.append(cur.strip()); cur = ""
        else: cur += ch
    if cur.strip(): parts.append(cur.strip())
    return parts

def _lit_eval(s: str) -> Any:
    node = ast.parse(s, mode="eval").body
    allowed = (ast.Constant, ast.Tuple, ast.List, ast.Dict, ast.UnaryOp, ast.BinOp, ast.BoolOp)
    if not isinstance(node, allowed): raise ValueError(f"Literals only: {s}")
    return eval(compile(ast.Expression(node), "<lit>", "eval"), {"__builtins__": {}}, {})

def parse_examples(lines: List[str]) -> List[Tuple[List[Any], Any]]:
    exs: List[Tuple[List[Any], Any]] = []
    for line in lines:
        m = _EX_LINE.match(line.strip())
        if not m: continue
        _fn, args_s, out_s = m.groups()
        args = [_lit_eval(p) for p in _split_args(args_s)] if args_s.strip() else []
        out = _lit_eval(out_s)
        exs.append((args, out))
    return exs

def parse_spec(text: str) -> Spec:
    lines = [l.rstrip() for l in text.splitlines()]
    funs: List[FunctionSpec] = []
    i = 0
    while i < len(lines):
        l = lines[i].strip()
        if l.startswith("- name:"):
            name = l.split(":",1)[1].strip(); i += 1
            args: List[Tuple[str,str]] = []; returns = "Any"
            ex_lines: List[str] = []; invariants: List[str] = []; pre: List[str] = []; post: List[str] = []
            while i < len(lines) and lines[i].strip():
                s = lines[i].strip()
                if s.startswith("args:"):
                    arglist = s.split(":",1)[1].strip()
                    if arglist:
                        for a in arglist.split(","):
                            a=a.strip()
                            if not a: continue
                            if ":" in a: an, at = a.split(":"); args.append((an.strip(), at.strip()))
                            else: args.append((a.strip(), "Any"))
                elif s.startswith("returns:"): returns = s.split(":",1)[1].strip()
                elif s.startswith("examples:") or s.startswith("invariants:") or s.startswith("pre:") or s.startswith("post:"):
                    pass
                elif s.startswith("- "):
                    body = s[2:].strip()
                    if "=" in body and _EX_LINE.match(body): ex_lines.append(body)
                    else:
                        if body.lower().startswith(("commutative","monotonic")): invariants.append(body)
                        elif "ret" in body or name in body: post.append(body)
                        else: invariants.append(body)
                elif s.lower().startswith("pre:"):
                    clause = s.split(":",1)[1].strip()
                    if clause: pre.append(clause)
                elif s.lower().startswith("post:"):
                    clause = s.split(":",1)[1].strip()
                    if clause: post.append(clause)
                i += 1
            examples = parse_examples(ex_lines)
            funs.append(FunctionSpec(name, args, returns, examples, invariants, pre, post))
        else:
            i += 1
    if not funs:
        funs = [FunctionSpec("add",[("a","int"),("b","int")],"int",
                             [([2,3],5),([10,-1],9),([0,0],0)],
                             ["commutative: add(a,b)==add(b,a)"], [], ["ret == a+b"])]
    return Spec(funs)

# ---------- Security ----------
FORBIDDEN_NAMES = {"__import__","eval","exec","open","compile","input","exit","quit","os","sys","subprocess","socket","pathlib","shutil","resource","ctypes","multiprocessing","threading","signal","builtins","globals","locals"}
ALLOWED_BUILTINS = {"abs": abs, "min": min, "max": max, "sum": sum, "len": len, "range": range, "enumerate": enumerate, "all": all, "any": any}

class SecurityViolation(Exception): pass
class SecurityAuditor(ast.NodeVisitor):
    def visit_Import(self, node): raise SecurityViolation("Imports forbidden")
    def visit_ImportFrom(self, node): raise SecurityViolation("Imports forbidden")
    def visit_Call(self, node):
        f = node.func
        if isinstance(f, ast.Name) and f.id in FORBIDDEN_NAMES: raise SecurityViolation(f"Forbidden call: {f.id}")
        if isinstance(f, ast.Attribute) and isinstance(f.value, ast.Name) and f.value.id in FORBIDDEN_NAMES: raise SecurityViolation(f"Forbidden attribute: {f.value.id}")
        self.generic_visit(node)
    def visit_Attribute(self, node):
        if isinstance(node.value, ast.Name) and node.value.id in FORBIDDEN_NAMES: raise SecurityViolation(f"Forbidden attribute: {node.value.id}")
        self.generic_visit(node)
    def visit_Name(self, node):
        if node.id in FORBIDDEN_NAMES: raise SecurityViolation(f"Forbidden name: {node.id}")
    def visit_Global(self, node): raise SecurityViolation("global forbidden")
    def visit_Nonlocal(self, node): raise SecurityViolation("nonlocal forbidden")
    def visit_With(self, node): raise SecurityViolation("with forbidden")
    def visit_Yield(self, node): raise SecurityViolation("yield forbidden")
    def visit_Await(self, node): raise SecurityViolation("async forbidden")
    def visit_ClassDef(self, node): raise SecurityViolation("classes forbidden")

def audit_source_secure(src: str) -> None:
    tree = ast.parse(src); SecurityAuditor().visit(tree)

# ---------- Sandbox ----------
class Sandbox:
    def __init__(self, cwd: Path, timeout_s: int): self.cwd = cwd; self.timeout_s = timeout_s
    def run_unittests(self) -> Tuple[int,str,str]:
        return self._run([sys.executable, "-m", "unittest", "discover", "-s", "tests", "-p", "test*.py", "-v"])
    def _run(self, cmd: List[str]) -> Tuple[int,str,str]:
        env = {"PYTHONPATH": str(self.cwd), "NO_COLOR":"1"}
        for k in list(os.environ.keys()):
            if k.lower().endswith("_proxy"): env[k] = ""
        proc = subprocess.Popen(cmd, cwd=self.cwd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, env=env, preexec_fn=os.setsid if hasattr(os,"setsid") else None)
        timer = threading.Timer(self.timeout_s, lambda: os.killpg(proc.pid, signal.SIGKILL) if hasattr(os,"killpg") else proc.kill())
        try: timer.start(); out, err = proc.communicate(); return proc.returncode, out, err
        finally: timer.cancel()

# ---------- Synthesis ----------
BIN_OPS = [(ast.Add,"+"),(ast.Sub,"-"),(ast.Mult,"*"),(ast.FloorDiv,"//"),(ast.Div,"/"),(ast.Mod,"%")]
CMP_OPS = [ast.Lt, ast.Gt, ast.Eq, ast.NotEq, ast.LtE, ast.GtE]
SAFE_FUNS_NUM = ["abs","min","max"]

@dataclass
class Candidate: src: str; passed: int; total: int; score: float

def _argnames(args: List[Tuple[str,str]]) -> List[str]: return [a for a,_ in args]
def sig_key_for_fs(fs: FunctionSpec) -> str:
    arg_sig = ",".join(t for _,t in fs.args)
    return f"{fs.name}|{arg_sig}|{fs.returns}"

def func_signature_str(fs: FunctionSpec) -> str:
    args = ", ".join(f"{n}: {t}" for n,t in fs.args)
    return f"{fs.name}({args}) -> {fs.returns}"

def post_bow_for_fs(fs: FunctionSpec) -> List[str]:
    return bow_tokens(" ".join(fs.post or []))

def _const_pool(fs: FunctionSpec) -> List[int]:
    ints: List[int] = []
    def rec(v: Any):
        if isinstance(v, bool): return
        if isinstance(v, int): ints.append(v); return
        if isinstance(v, float) and abs(v - int(v)) < 1e-9: ints.append(int(v)); return
        if isinstance(v, (list, tuple)):
            for z in v: rec(z)
    for args, res in fs.examples:
        for a in args: rec(a)
        rec(res)
    ints.extend([0,1,-1,2,-2,10,-10,3,-3])
    seen, out = set(), []
    for k in sorted(ints, key=lambda x:(abs(x),x)):
        if k not in seen: seen.add(k); out.append(k)
    return out

def _wrap_func(name: str, args: List[str], body_expr: ast.AST) -> str:
    aargs = [ast.arg(arg=a) for a in args]
    guard = ast.parse(textwrap.dedent("""
    _AUR_DEPTH = 0
    def _aur_guard():
        global _AUR_DEPTH
        _AUR_DEPTH += 1
        if _AUR_DEPTH > 50:
            raise RecursionError("depth")
    def _aur_unguard():
        global _AUR_DEPTH
        _AUR_DEPTH -= 1
    """)).body
    fn = ast.FunctionDef(
        name=name,
        args=ast.arguments(posonlyargs=[], args=aargs, kwonlyargs=[], kw_defaults=[], defaults=[]),
        body=[
            ast.Expr(ast.Call(func=ast.Name("_aur_guard", ast.Load()), args=[], keywords=[])),
            ast.Try(body=[ast.Return(value=body_expr)], handlers=[ast.ExceptHandler(type=None, name=None, body=[ast.Raise()])], orelse=[], finalbody=[ast.Expr(ast.Call(func=ast.Name("_aur_unguard", ast.Load()), args=[], keywords=[]))])
        ],
        decorator_list=[], type_comment=None
    )
    mod = ast.Module(body=guard+[fn], type_ignores=[]); ast.fix_missing_locations(mod); return ast.unparse(mod)

def _size(node: ast.AST) -> int: return sum(1 for _ in ast.walk(node))
def _mk_bin(a: ast.AST,b: ast.AST,op: ast.AST)->ast.AST: return ast.BinOp(left=a, op=op(), right=b)
def _mk_if(test: ast.AST, a: ast.AST, b: ast.AST)->ast.AST: return ast.IfExp(test=test, body=a, orelse=b)
def _mk_call(name:str, args:List[ast.AST])->ast.AST: return ast.Call(func=ast.Name(id=name, ctx=ast.Load()), args=args, keywords=[])

def _terms_for_types(argnames: List[str], types: List[str], consts: List[int]) -> List[ast.AST]:
    terms: List[ast.AST] = []
    for a in argnames: terms.append(ast.Name(id=a, ctx=ast.Load()))
    for c in consts: terms.append(ast.Constant(value=c))
    for a,t in zip(argnames, types):
        na = ast.Name(id=a, ctx=ast.Load())
        if t in ("int","float","number","Any"): terms.extend([_mk_call("abs",[na])])
        if t.startswith("list"): terms.extend([_mk_call("len",[na]), _mk_call("sum",[na])])
        if t == "str": terms.extend([_mk_call("len",[na])])
    return terms

def _valid_defines(name: str, src: str) -> bool:
    try:
        t = ast.parse(src)
        for n in t.body:
            if isinstance(n, ast.FunctionDef) and n.name == name:
                return True
    except Exception:
        return False
    return False

def enumerate_candidates(fs: FunctionSpec, available_callees: List[Tuple[str,int,List[str]]],
                         beam: int, prior_srcs: Optional[List[str]] = None) -> List[str]:
    argnames = _argnames(fs.args); types = [t for _,t in fs.args]
    consts = _const_pool(fs)
    base = _terms_for_types(argnames, types, consts); cands: List[Tuple[int, ast.AST]] = []

    seeded: List[str] = []
    for snip in (prior_srcs or []):
        try:
            audit_source_secure(snip)
            if _valid_defines(fs.name, snip): seeded.append(snip)
        except Exception: continue

    for t in base:
        if isinstance(t, (ast.Name, ast.Constant)):
            for f in SAFE_FUNS_NUM: cands.append((_size(t)+1, _mk_call(f,[t])))
    for a in base:
        for b in base:
            for OP,_ in BIN_OPS: cands.append((_size(a)+_size(b)+1, _mk_bin(a,b,OP)))
    for a in base[:6]:
        for b in base[:6]:
            for CMP in CMP_OPS:
                test = ast.Compare(left=a, ops=[CMP()], comparators=[b])
                for body in base[:3]:
                    for other in base[:3]: cands.append((_size(test)+_size(body)+_size(other), _mk_if(test, body, other)))
    for callee, arity, _ in available_callees:
        if 0 < arity <= len(argnames):
            sel = [ast.Name(id=argnames[i], ctx=ast.Load()) for i in range(arity)]
            cands.append((2+arity, _mk_call(callee, sel)))
    extra=[]
    for (sa,ea) in cands[:beam]:
        for (sb,eb) in cands[:max(1,beam//2)]:
            for OP,_ in BIN_OPS: extra.append((sa+sb+1, _mk_bin(ea, eb, OP)))
    cands.extend(extra)
    cands.sort(key=lambda x:x[0])

    out: List[str] = []
    out.extend(seeded[:max(0, beam//3)])  # reserve ~1/3 for seeded
    for _,expr in cands[:max(beam - len(out), 0)]:
        try: fn_src = _wrap_func(fs.name, argnames, expr); audit_source_secure(fn_src); out.append(fn_src)
        except Exception: continue

    if not out:
        if len(argnames)>=2: out=[_wrap_func(fs.name, argnames, _mk_bin(ast.Name(argnames[0],ast.Load()), ast.Name(argnames[1],ast.Load()), ast.Add))]
        else: out=[_wrap_func(fs.name, argnames, ast.Name(argnames[0],ast.Load()))]
    return out

def approx_equal(a: Any, b: Any) -> bool:
    if isinstance(a, float) or isinstance(b, float):
        try: return math.isclose(float(a), float(b), rel_tol=1e-9, abs_tol=1e-9)
        except Exception: return False
    return a == b

def distance(a: Any, b: Any) -> float:
    try: return abs(float(a) - float(b))
    except Exception: return 0.0 if a==b else 1.0

# ---------- Compile & Check ----------
def compile_module(module_src: str) -> Dict[str, Any]:
    glb = {"__builtins__": ALLOWED_BUILTINS.copy()}; loc: Dict[str,Any] = {}
    audit_source_secure(module_src); code = compile(module_src, "<module>", "exec"); exec(code, glb, loc); return loc

def eval_condition(expr: str, env: Dict[str, Any]) -> bool:
    try: node = ast.parse(expr, mode="eval").body
    except Exception: return False
    allowed = (ast.Expression, ast.BoolOp, ast.BinOp, ast.UnaryOp, ast.Compare, ast.Call, ast.Name, ast.Load, ast.Constant, ast.IfExp, ast.Subscript, ast.Tuple, ast.List, ast.Dict)
    for n in ast.walk(ast.Expression(node)):
        if not isinstance(n, allowed): return False
    try: return bool(eval(compile(ast.Expression(node), "<cond>", "eval"), {"__builtins__": ALLOWED_BUILTINS}, env))
    except Exception: return False

def run_examples_with_post(module_src: str, fname: str, argnames: List[str], examples: List[Tuple[List[Any],Any]], postconds: List[str]) -> Tuple[int,int,float]:
    loc = compile_module(module_src); f = loc.get(fname)
    if not callable(f): return 0, len(examples), 1e9
    passed=0; errsum=0.0; total=len(examples)
    for args, out in examples:
        env = {**{argnames[i]: args[i] for i in range(len(args))}}
        try:
            ret = f(*args); env["ret"]=ret
            posts_ok = all(eval_condition(pc, {**env, **loc}) for pc in postconds) if postconds else True
            if approx_equal(ret,out) and posts_ok: passed += 1
            else: errsum += distance(ret,out) + (0 if posts_ok else 0.5)
        except Exception: errsum += 1e3
    score = (len(module_src)*0.0005) + errsum - passed*12.0
    return passed, total, score

# ---------- Metrics ----------
def cyclomatic_complexity(src: str) -> int:
    try: t = ast.parse(src)
    except Exception: return 999
    comp = 1
    for n in ast.walk(t):
        if isinstance(n,(ast.If, ast.For, ast.While, ast.And, ast.Or, ast.Try)): comp += 1
    return comp

def fn_complexity(snippet: str, fn_name: str) -> int:
    try:
        t = ast.parse(snippet)
        for n in t.body:
            if isinstance(n, ast.FunctionDef) and n.name == fn_name:
                return sum(1 for _ in ast.walk(n))
    except Exception:
        return -1
    return -1

def calls_in_function(snippet: str, fn_name: str) -> List[str]:
    try:
        t = ast.parse(snippet); calls: List[str] = []
        class V(ast.NodeVisitor):
            def __init__(self): self.in_fn=False
            def visit_FunctionDef(self, n: ast.FunctionDef):
                if n.name == fn_name:
                    self.in_fn=True; self.generic_visit(n); self.in_fn=False
                # skip others
            def visit_Call(self, n: ast.Call):
                if self.in_fn and isinstance(n.func, ast.Name):
                    calls.append(n.func.id)
                self.generic_visit(n)
        V().visit(t)
        # unique preserve order
        seen, out = set(), []
        for c in calls:
            if c not in seen:
                seen.add(c); out.append(c)
        return out
    except Exception:
        return []

def mutate_source(src: str) -> str:
    try: tree = ast.parse(src)
    except Exception: return src
    class Mut(ast.NodeTransformer):
        def visit_BinOp(self, node):
            self.generic_visit(node)
            if random.random() < 0.35: node.op = random.choice([ast.Add(), ast.Sub(), ast.Mult(), ast.Div(), ast.FloorDiv(), ast.Mod()])
            return node
        def visit_Constant(self, node):
            if isinstance(node.value, int) and random.random() < 0.35:
                return ast.copy_location(ast.Constant(value=node.value + random.choice([-2,-1,1,2,10,-10])), node)
            return node
        def visit_IfExp(self, node):
            self.generic_visit(node)
            if random.random() < 0.25: node.body, node.orelse = node.orelse, node.body
            return node
    mt = Mut().visit(tree); ast.fix_missing_locations(mt)
    try: return ast.unparse(mt)
    except Exception: return src

def extract_call_graph(module_src: str, fnames: List[str]) -> Dict[str, List[str]]:
    try: t = ast.parse(module_src)
    except Exception: return {fn: [] for fn in fnames}
    idx = {fn:i for i,fn in enumerate(fnames)}; calls: Dict[str, List[str]] = {fn: [] for fn in fnames}
    class V(ast.NodeVisitor):
        def __init__(self): self.cur=None
        def visit_FunctionDef(self, n: ast.FunctionDef): self.cur=n.name; self.generic_visit(n); self.cur=None
        def visit_Call(self, n: ast.Call):
            if self.cur and isinstance(n.func, ast.Name):
                cal = n.func.id
                if cal in idx and cal != self.cur and cal not in calls[self.cur]: calls[self.cur].append(cal)
            self.generic_visit(n)
    V().visit(t); return calls

def write_html_report(repo: Repo, spec: Spec) -> None:
    md = read_file(repo.path("AURORA_REPORT.md"))
    cfg = json.loads(read_file(repo.path("run_config.json")))
    graph = json.loads(read_file(repo.path("call_graph.json"))) if (repo.path("call_graph.json")).exists() else {"nodes":[f.name for f in spec.functions],"edges":{}}
    body = f"""<!doctype html><html><head><meta charset="utf-8"><title>AURORA-X Report</title>
<style>body{{font-family:system-ui,Segoe UI,Roboto,sans-serif;margin:24px}}pre,code{{background:#f6f8fa;padding:12px;overflow:auto}}</style>
</head><body>
<h1>AURORA-X Ultra</h1>
<p><b>Run:</b> {repo.root}</p>
<h3>Config</h3><pre>{json.dumps(cfg, indent=2)}</pre>
<h3>Call Graph</h3><pre>{json.dumps(graph, indent=2)}</pre>
<h3>Report</h3><pre>{md}</pre>
</body></html>"""
    write_file(repo.path("report.html"), body)

# ---------- Orchestrator ----------
class AuroraX:
    def __init__(self, seed: int, max_iters: int, beam: int, timeout_s: int, outdir: Optional[Path], rng_cfg: Dict[str, Any]):
        random.seed(seed); self.repo = Repo.create(outdir); self.sandbox = Sandbox(self.repo.root, timeout_s=timeout_s)
        self.beam = beam; self.max_iters = max_iters; self.rng_cfg = rng_cfg

    def plan(self, spec: Spec) -> None:
        steps = ["Parse spec","Generate tests","Synthesize AST with corpus priming","Sandbox tests","Mutate/resynthesize","Export graph/scores/config/report"]
        write_file(self.repo.path("AURORA_PLAN.md"), "# Plan\n\n" + "\n".join(f"- {s}" for s in steps))

    def save_run_config(self, cfg: Dict[str, Any]) -> None:
        write_file(self.repo.path("run_config.json"), json.dumps(cfg, indent=2))

    def _db_path(self) -> Path:
        # use runs/corpus.db if under runs/run-*, else local repo dir
        return (self.repo.root.parent / "corpus.db") if self.repo.root.name.startswith("run-") else (self.repo.root / "corpus.db")

    def synthesize_best(self, fs: FunctionSpec, available_callees: List[Tuple[str,int,List[str]]], base_prefix: str, iter_idx: int) -> Candidate:
        # prior snippets: same-name + similar(signature/post)
        db_path = self._db_path()
        same_name = top_snippets(db_path, fs.name, limit=max(1, self.beam // 6))
        similar = top_snippets_similar(db_path, sig_key_for_fs(fs), post_bow_for_fs(fs), limit=max(1, self.beam // 6))
        prior = []
        seen = set()
        for s in same_name + similar:
            if s not in seen: prior.append(s); seen.add(s)
        start = time.time()
        cands = enumerate_candidates(fs, available_callees, beam=self.beam, prior_srcs=prior)
        scored: List[Candidate] = []
        for fn_src in cands:
            module_src = base_prefix + "\n\n" + fn_src + "\n"
            try: p,t,sc = run_examples_with_post(module_src, fs.name, [a for a,_ in fs.args], fs.examples, fs.post)
            except Exception: p,t,sc = 0, len(fs.examples), 1e9
            scored.append(Candidate(fn_src, p, t, sc))
        dur_ms = int((time.time() - start) * 1000)
        scored.sort(key=lambda c:(-(c.passed), c.score))
        best = scored[0]
        # record candidate stats
        func_sig = func_signature_str(fs)
        comp = fn_complexity(best.src, fs.name)
        calls = calls_in_function(best.src, fs.name)
        corpus_record(
            self.repo.root,
            spec_text=self._spec_text_cache,
            func_name=fs.name,
            func_signature=func_sig,
            snippet=best.src,
            passed=best.passed, total=best.total, score=best.score,
            iteration=iter_idx,
            failing_tests=[],  # unit test names not surfaced here
            complexity=comp,
            calls_functions=calls,
            sig_key=sig_key_for_fs(fs),
            post_bow=post_bow_for_fs(fs),
            duration_ms=dur_ms,
            synthesis_method="ast_beam",
        )
        return best

    def build_module(self, spec: Spec, fun_map: Dict[str,str]) -> str:
        src = "# Generated by AURORA-X (offline synthesis)\n\n" + "\n\n".join(fun_map[f.name] for f in spec.functions) + "\n"
        audit_source_secure(src)
        if cyclomatic_complexity(src) > 250: raise SecurityViolation("Complexity too high")
        return src

    def export_graph_and_scores(self, spec: Spec, module_src: str, iter_idx: int) -> None:
        names = [f.name for f in spec.functions]; graph = extract_call_graph(module_src, names)
        write_file(self.repo.path("call_graph.json"), json.dumps({"nodes": names, "edges": graph}, indent=2))
        for f in spec.functions:
            p,t,sc = run_examples_with_post(module_src, f.name, [a for a,_ in f.args], f.examples, f.post)
            jsonl_append(self.repo.path("logs/scores.jsonl"), {"ts": now(), "iter": iter_idx, "function": f.name, "passed": p, "total": t, "score": sc})

    def run(self, spec_text: str) -> Tuple[Repo,bool]:
        self._spec_text_cache = spec_text  # needed for corpus_record
        spec = parse_spec(spec_text); self.plan(spec)
        cfg = {"beam": self.beam, "max_iters": self.max_iters, "timeout_s": self.sandbox.timeout_s, "rng": self.rng_cfg}
        self.save_run_config(cfg)
        tests_src = gen_unittests(spec, self.rng_cfg); write_file(self.repo.path("tests/test_app.py"), tests_src); self.repo.set_hash("tests/test_app.py", tests_src)

        best_map: Dict[str,str] = {}
        for idx, f in enumerate(spec.functions):
            prefix = "\n\n".join(best_map[name] for name in [g.name for g in spec.functions[:idx]]) if idx>0 else ""
            callees_meta = [(g.name, len(g.args), [t for _,t in g.args]) for g in spec.functions[:idx]]
            cand = self.synthesize_best(f, callees_meta, base_prefix=prefix, iter_idx=0)
            best_map[f.name] = cand.src

        module_src = self.build_module(spec, best_map); write_file(self.repo.path("src/app.py"), module_src); self.repo.set_hash("src/app.py", module_src)
        self.export_graph_and_scores(spec, module_src, 0)

        for it in range(1, self.max_iters+1):
            rc, out, err = self.sandbox.run_unittests()
            self.append_report(it, out, err)
            jsonl_append(self.repo.path("logs/trace.jsonl"), {"ts": now(), "iter": it, "rc": rc, "out_tail": out[-900:], "err_tail": err[-900:]})
            self.verify_integrity(); self.export_graph_and_scores(spec, read_file(self.repo.path("src/app.py")), it)
            if rc == 0:
                write_html_report(self.repo, spec); return self.repo, True

            improved=False
            # mutate step
            for idx, f in enumerate(spec.functions):
                mutated = mutate_source(best_map[f.name])
                prefix = "\n\n".join(best_map[name] if name != f.name else "" for name in [g.name for g in spec.functions[:idx]])
                assembled = (prefix + "\n\n" + mutated + "\n\n" + "\n\n".join(best_map[name] for name in [g.name for g in spec.functions[idx+1:]]))
                try:
                    p,t,sc = run_examples_with_post(assembled, f.name, [a for a,_ in f.args], f.examples, f.post)
                    p0,_,sc0 = run_examples_with_post(self.build_module(spec, best_map), f.name, [a for a,_ in f.args], f.examples, f.post)
                    if (p>p0) or (p==p0 and sc<sc0):
                        best_map[f.name] = mutated; improved=True
                        # record the mutated improvement
                        corpus_record(
                            self.repo.root,
                            spec_text=self._spec_text_cache,
                            func_name=f.name,
                            func_signature=func_signature_str(f),
                            snippet=mutated, passed=p, total=t, score=sc,
                            iteration=it,
                            failing_tests=[],
                            complexity=fn_complexity(mutated, f.name),
                            calls_functions=calls_in_function(mutated, f.name),
                            sig_key=sig_key_for_fs(f),
                            post_bow=post_bow_for_fs(f),
                            duration_ms=0,
                            synthesis_method="mutate",
                        )
                except Exception:
                    pass

            # reseed if not improved
            if not improved:
                for idx, f in enumerate(spec.functions):
                    prefix = "\n\n".join(best_map[name] for name in [g.name for g in spec.functions[:idx]]) if idx>0 else ""
                    callees_meta = [(g.name, len(g.args), [t for _,t in g.args]) for g in spec.functions[:idx]]
                    alt = self.synthesize_best(f, callees_meta, base_prefix=prefix, iter_idx=it)
                    try:
                        curp,_,curs = run_examples_with_post(self.build_module(spec, best_map), f.name, [a for a,_ in f.args], f.examples, f.post)
                        module_try = prefix + "\n\n" + alt.src + "\n\n" + "\n\n".join(best_map[name] for name in [g.name for g in spec.functions[idx+1:]])
                        newp,_,news = run_examples_with_post(module_try, f.name, [a for a,_ in f.args], f.examples, f.post)
                        if (newp>curp) or (newp==curp and news<curs):
                            best_map[f.name] = alt.src
                            corpus_record(
                                self.repo.root,
                                spec_text=self._spec_text_cache,
                                func_name=f.name,
                                func_signature=func_signature_str(f),
                                snippet=alt.src, passed=newp, total=len(f.examples), score=news,
                                iteration=it,
                                failing_tests=[],
                                complexity=fn_complexity(alt.src, f.name),
                                calls_functions=calls_in_function(alt.src, f.name),
                                sig_key=sig_key_for_fs(f),
                                post_bow=post_bow_for_fs(f),
                                duration_ms=0,
                                synthesis_method="alt_beam",
                            )
                    except Exception:
                        pass

            module_src = self.build_module(spec, best_map); write_file(self.repo.path("src/app.py"), module_src); self.repo.set_hash("src/app.py", module_src)

        write_html_report(self.repo, spec); return self.repo, False

    def append_report(self, it: int, out: str, err: str) -> None:
        report = f"\n\n## Iteration {it}\n\n### Unit Tests\n```\n{out}\n{err}\n```\n"
        with self.repo.path("AURORA_REPORT.md").open("a", encoding="utf-8") as f: f.write(report)

    def verify_integrity(self) -> None:
        for rel in ["tests/test_app.py","src/app.py"]:
            p = self.repo.path(rel)
            if not p.exists(): raise SecurityViolation(f"Missing file: {rel}")
            audit_source_secure(read_file(p))
        self.repo.set_hash("tests/test_app.py", read_file(self.repo.path("tests/test_app.py"))); self.repo.set_hash("src/app.py", read_file(self.repo.path("src/app.py")))

# ---------- CLI ----------
def cli_entry() -> None:
    ap = argparse.ArgumentParser(description="AURORA-X Ultra (Offline)")
    g = ap.add_mutually_exclusive_group(required=True)
    g.add_argument("--spec", type=str, help="Inline spec text (Markdown DSL)")
    g.add_argument("--spec-file", type=str, help="Path to spec file")
    ap.add_argument("--max-iters", type=int, default=20)
    ap.add_argument("--beam", type=int, default=100)
    ap.add_argument("--timeout", type=int, default=12)
    ap.add_argument("--seed", type=int, default=1337)
    ap.add_argument("--outdir", type=str, default="./runs")
    ap.add_argument("--int-min", type=int, default=-8)
    ap.add_argument("--int-max", type=int, default=8)
    ap.add_argument("--float-min", type=float, default=-2.0)
    ap.add_argument("--float-max", type=float, default=2.0)
    ap.add_argument("--list-len-min", type=int, default=0)
    ap.add_argument("--list-len-max", type=int, default=5)
    ap.add_argument("--str-chars", type=str, default="abc")
    args = ap.parse_args()

    rng_cfg = {"int_min": args.int_min, "int_max": args.int_max, "float_min": args.float_min, "float_max": args.float_max, "list_len_min": args.list_len_min, "list_len_max": args.list_len_max, "str_chars": args.str_chars}
    spec_text = args.spec if args.spec is not None else read_file(Path(args.spec_file))
    outdir = Path(args.outdir).resolve() if args.outdir else None

    ax = AuroraX(seed=args.seed, max_iters=args.max_iters, beam=args.beam, timeout_s=args.timeout, outdir=outdir, rng_cfg=rng_cfg)
    repo, ok = ax.run(spec_text)
    print(f"[AURORA-X] Repo: {repo.root}"); print(f"[AURORA-X] Status: {'PASS' if ok else 'INCOMPLETE'}")
    print("[AURORA-X] Files:")
    for f in repo.list_files(): print(" -", f)
    print(f"\nOpen HTML report: file://{repo.path('report.html')}")

Decisions (so you don’t get confused later)
	•	Required fields: id, timestamp, spec_id, spec_hash, func_name, func_signature, passed, total, score, snippet.
	•	Optional but captured: complexity, iteration, calls_functions, duration_ms, synthesis_method, sig_key, post_bow, failing_tests.
	•	Arrays format: JSON strings in DB (TEXT), same JSON also mirrored in corpus.jsonl.
	•	Timestamp: ISO 8601 Z (UTC).
	•	Indexes: added per your list + sig_key.
	•	Compatibility: legacy DBs auto-migrate columns safely.

a. Want a aurorax corpus top --func <name> CLI to print best N with scores and complexities?
b. Add HTML “Seeding” panel listing which prior snippets were pulled (same-name vs similar) with similarity breakdown?