we’re launching Architecture C (Hybrid Universal Runtime). Below is PACK 1: AuroraOS Core (Universal Runtime Layer) — a complete, copy-paste, ready-to-run core: orchestrator, module/plugin loader, safe sandbox runner, minimal AuroraLink (local P2P) server, updater stub, logging/telemetry, CLI wrappers and quick tests. This is the heart of AuroraOS: powerful, modular, and ready to attach Edge runtimes later.

Implementation choices: Python 3.11+ for the core (portable, rich libs, easy to extend), optional native modules for hot paths. Everything runs locally by design — no external APIs required.

PACK 1 — Files to add now

Create these files (paths shown). Copy each full block into the exact path.

1) aurora_core/orchestrator.py — core orchestrator, module loader, watchdog, update stub

Path: aurora_core/orchestrator.py

#!/usr/bin/env python3
"""
Aurora Core Orchestrator
- module/plugin loader
- process supervisor + watchdog
- simple AuroraLink (WebSocket) server for internal device comms
- sandboxed module runner (resource-limited subprocess)
- update stub (safe in-repo updater)
"""

import os
import sys
import json
import time
import signal
import shutil
import logging
import threading
import subprocess
from pathlib import Path
from typing import Dict, Optional, Callable, Any
import psutil
import asyncio
import functools

# Optional dependencies: websockets, fastapi/uvicorn if you want REST control
# pip install psutil websockets

ROOT = Path(__file__).resolve().parents[1]
LOG_DIR = ROOT / "aurora_logs"
MODULES_DIR = ROOT / "aurora_modules"
PID_DIR = ROOT / ".aurora" / "pids"
LOG_DIR.mkdir(parents=True, exist_ok=True)
MODULES_DIR.mkdir(parents=True, exist_ok=True)
PID_DIR.mkdir(parents=True, exist_ok=True)

logger = logging.getLogger("aurora.orchestrator")
handler = logging.FileHandler(LOG_DIR / "orchestrator.log")
handler.setFormatter(logging.Formatter("%(asctime)s %(levelname)s %(message)s"))
logger.addHandler(handler)
logger.setLevel(logging.INFO)

# -------------------------
# Utilities
# -------------------------
def write_pid(name: str, pid: int):
    p = PID_DIR / f"{name}.pid"
    p.write_text(str(pid))

def read_pid(name: str) -> Optional[int]:
    p = PID_DIR / f"{name}.pid"
    if not p.exists():
        return None
    try:
        return int(p.read_text().strip())
    except:
        return None

def remove_pid(name: str):
    try:
        (PID_DIR / f"{name}.pid").unlink()
    except:
        pass

def now_iso(): return time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime())

# -------------------------
# Module plugin loader
# -------------------------
class Plugin:
    def __init__(self, path: Path):
        self.path = path
        self.meta = {}
        self.name = path.stem
        self.entry = None
        self.load_meta()

    def load_meta(self):
        meta_file = self.path / "module.json"
        if not meta_file.exists():
            return
        try:
            self.meta = json.loads(meta_file.read_text(encoding="utf8"))
            self.entry = self.meta.get("entry", "run.py")
        except Exception as e:
            logger.error("failed loading meta for %s: %s", self.name, e)

    def start(self, args=None, env=None):
        runner = self.path / self.entry
        if not runner.exists():
            raise FileNotFoundError(f"entry not found {runner}")
        return SandboxRunner.start_process(self.name, [sys.executable, str(runner)] + (args or []), cwd=str(self.path), env=env)

# -------------------------
# Sandbox runner (process with resource limits)
# -------------------------
class SandboxRunner:
    @staticmethod
    def start_process(name: str, cmd: list, cwd: str = ".", env: Optional[dict] = None, cpu_limit_pct: Optional[int] = None):
        """
        Start process and restrict resources lightly using psutil where possible.
        For stronger sandboxing, run in containers or use OS-level cgroups.
        """
        logger.info("starting sandboxed process %s: %s", name, cmd)
        proc = subprocess.Popen(cmd, cwd=cwd, env=(env or os.environ.copy()))
        write_pid(name, proc.pid)
        # best-effort resource limiting (deferred to watchdog thread)
        return proc

    @staticmethod
    def kill_process(name: str):
        pid = read_pid(name)
        if not pid:
            return False
        try:
            p = psutil.Process(pid)
            p.terminate()
            p.wait(timeout=5)
        except Exception:
            try:
                p.kill()
            except Exception:
                pass
        remove_pid(name)
        return True

# -------------------------
# Supervisor + watchdog
# -------------------------
class Supervisor:
    def __init__(self, check_interval=2.0, restart_on_crash=True):
        self.services: Dict[str, subprocess.Popen] = {}
        self.lock = threading.Lock()
        self.check_interval = check_interval
        self.restart_on_crash = restart_on_crash
        self.running = False
        self._thread = None

    def register_service(self, name: str, start_fn: Callable[[], subprocess.Popen]):
        with self.lock:
            if name in self.services:
                logger.warning("service %s already registered", name)
                return
            p = start_fn()
            self.services[name] = p
            logger.info("registered service %s pid=%s", name, getattr(p, "pid", None))

    def start(self):
        self.running = True
        self._thread = threading.Thread(target=self._loop, daemon=True, name="supervisor-loop")
        self._thread.start()
        logger.info("supervisor started")

    def stop(self):
        self.running = False
        with self.lock:
            for name, proc in list(self.services.items()):
                try:
                    proc.terminate()
                    proc.wait(timeout=3)
                except Exception:
                    try: proc.kill()
                    except: pass
                remove_pid(name)
                logger.info("service %s stopped", name)
        logger.info("supervisor stopped")

    def _loop(self):
        while self.running:
            time.sleep(self.check_interval)
            with self.lock:
                for name, proc in list(self.services.items()):
                    if proc.poll() is not None:
                        logger.warning("service %s exited with code %s", name, proc.returncode)
                        remove_pid(name)
                        self.services.pop(name, None)
                        if self.restart_on_crash:
                            logger.info("restarting %s", name)
                            # naive restart: find plugin and start again
                            plugin_path = MODULES_DIR / name
                            if plugin_path.exists():
                                try:
                                    plugin = Plugin(plugin_path)
                                    newp = plugin.start()
                                    self.services[name] = newp
                                except Exception as e:
                                    logger.error("failed to restart %s: %s", name, e)

# -------------------------
# AuroraLink (WebSocket) - simple P2P hub (local-only)
# -------------------------
# Lightweight asyncio+websockets server providing a local pub/sub.
try:
    import websockets
except Exception:
    websockets = None

class AuroraLink:
    def __init__(self, host="0.0.0.0", port=9801):
        self.host = host
        self.port = port
        self.clients = set()
        self.server = None

    async def handler(self, websocket, path):
        self.clients.add(websocket)
        addr = websocket.remote_address
        logger.info("auroralink client connected %s", addr)
        try:
            async for message in websocket:
                # simple JSON envelope expected
                try:
                    obj = json.loads(message)
                except:
                    obj = {"raw": message}
                # echo to all for now (local hub)
                await self.broadcast(obj, sender=websocket)
        except Exception as e:
            logger.info("auroralink client disconnect %s: %s", addr, e)
        finally:
            self.clients.remove(websocket)

    async def broadcast(self, obj, sender=None):
        m = json.dumps(obj)
        await asyncio.wait([c.send(m) for c in self.clients if c is not sender])

    async def serve(self):
        if not websockets:
            logger.warning("websockets not installed; auroralink disabled")
            return
        self.server = await websockets.serve(self.handler, self.host, self.port)
        logger.info("auroralink running on %s:%s", self.host, self.port)
        await self.server.wait_closed()

    def run_in_thread(self):
        if not websockets:
            return
        loop = asyncio.new_event_loop()
        t = threading.Thread(target=functools.partial(loop.run_until_complete, self.serve()), daemon=True)
        t.start()

# -------------------------
# Updater stub (safe)
# -------------------------
class Updater:
    """
    Minimal safe updater: for production use code-signing + atomic swaps.
    This stub demonstrates:
      - fetch update to staging dir
      - validate (checksum/signature) - omitted for brevity
      - swap directories atomically
    """
    STAGING = ROOT / ".aurora_updates" / "staging"
    STAGING.mkdir(parents=True, exist_ok=True)

    @staticmethod
    def stage_archive(archive_path: str):
        # user provides a tarball; we extract to staging and validate
        import tarfile
        try:
            with tarfile.open(archive_path, "r:*") as tf:
                tf.extractall(Updater.STAGING)
            logger.info("staged update from %s", archive_path)
            return True
        except Exception as e:
            logger.error("failed stage update: %s", e)
            return False

    @staticmethod
    def activate_staging():
        # **DANGEROUS**: real world requires signatures + backups + validators
        backup = ROOT / ".aurora_backup"
        if backup.exists():
            shutil.rmtree(backup)
        shutil.copytree(ROOT, backup, dirs_exist_ok=True)
        # copy staged content into place (very naive)
        for item in Updater.STAGING.iterdir():
            target = ROOT / item.name
            if target.exists():
                if target.is_dir():
                    shutil.rmtree(target)
                else:
                    target.unlink()
            if item.is_dir():
                shutil.copytree(item, target)
            else:
                shutil.copy2(item, target)
        logger.info("activated staging update (backup saved)")
        return True

# -------------------------
# Example orchestration entrypoint
# -------------------------
def load_plugins():
    plugins = {}
    for child in MODULES_DIR.iterdir():
        if child.is_dir():
            p = Plugin(child)
            plugins[p.name] = p
    return plugins

def main_loop():
    sup = Supervisor()
    plugins = load_plugins()
    # register each plugin to supervisor
    for name, plugin in plugins.items():
        try:
            sup.register_service(name, lambda p=plugin: p.start())
        except Exception as e:
            logger.exception("failed register plugin %s: %s", name, e)
    sup.start()
    # start auroralink
    link = AuroraLink()
    try:
        link.run_in_thread()
    except Exception:
        pass
    # run until killed
    try:
        while True:
            time.sleep(1)
    except KeyboardInterrupt:
        logger.info("shutdown requested")
        sup.stop()

if __name__ == "__main__":
    main_loop()

2) aurora_core/plugin_template/module.json and aurora_core/plugin_template/run.py — example plugin

Path: aurora_core/plugin_template/module.json

{
  "name": "example-plugin",
  "version": "0.1.0",
  "entry": "run.py",
  "description": "Example plugin for Aurora Core: simple echo service"
}


Path: aurora_core/plugin_template/run.py

#!/usr/bin/env python3
import time, os, sys, json
from pathlib import Path

ROOT = Path(__file__).resolve().parents[1]
log = ROOT / "aurora_logs" / "example-plugin.out.log"
log.parent.mkdir(parents=True, exist_ok=True)

def main():
    i = 0
    with open(log, "a") as fh:
        while True:
            fh.write(f"{__name__} alive {i}\\n")
            fh.flush()
            i += 1
            time.sleep(5)

if __name__ == "__main__":
    main()


After you add these, copy plugin_template/ into aurora_modules/example-plugin (or just move).

3) aurora_core/edge_runtime.py — minimal Edge runtime (for small devices)

Path: aurora_core/edge_runtime.py

#!/usr/bin/env python3
"""
Aurora Edge runtime - minimal footprint runtime for constrained devices.
Connects to local AuroraLink hub (or to a central core) and responds to commands.
"""

import asyncio
import json
import os
import time
from pathlib import Path
try:
    import websockets
except:
    websockets = None

AURORA_LINK = os.environ.get("AURORA_LINK", "ws://127.0.0.1:9801")
ID = os.environ.get("AURORA_EDGE_ID", f"edge-{os.getpid()}")

async def run():
    if not websockets:
        print("websockets missing; pip install websockets")
        return
    async with websockets.connect(AURORA_LINK) as ws:
        await ws.send(json.dumps({"type":"hello","id":ID}))
        while True:
            msg = await ws.recv()
            obj = json.loads(msg)
            # very simple: respond to ping
            if obj.get("type") == "ping":
                await ws.send(json.dumps({"type":"pong","id":ID, "ts": time.time()}))

if __name__ == "__main__":
    asyncio.run(run())

4) aurora_core/cli.py — lightweight CLI to start/stop/status via orchestrator

Path: aurora_core/cli.py

#!/usr/bin/env python3
import sys
from pathlib import Path
ROOT = Path(__file__).resolve().parents[1]
sys.path.insert(0, str(ROOT / "aurora_core"))
from orchestrator import main_loop
from orchestrator import start_watchdog

def usage():
    print("usage: python -m aurora_core.cli start|stop|status (stop/status are basic)")

if __name__ == "__main__":
    if len(sys.argv) < 2:
        usage(); sys.exit(1)
    cmd = sys.argv[1]
    if cmd == "start":
        main_loop()
    elif cmd == "status":
        print("status: processes in .aurora/pids (inspect logs in aurora_logs)")
    elif cmd == "stop":
        print("stop: terminate orchestrator via SIGINT or kill pid")
    else:
        usage()

5) aurora_modules/example-plugin — copy plugin_template here

Copy the plugin_template directory into aurora_modules/example-plugin. (I gave files above.)

6) aurora_os.py — top-level entrypoint (thin wrapper)

Path: aurora_os.py

#!/usr/bin/env python3
"""
Top-level entrypoint for AuroraOS (Hybrid Core)
"""
from pathlib import Path
import os, sys

ROOT = Path(__file__).resolve().parents[0]
# prefer virtualenv python
sys.path.insert(0, str(ROOT / "aurora_core"))

from orchestrator import main_loop

if __name__ == "__main__":
    main_loop()

7) tools/aurora_cli_wrapper.sh — quick shell wrapper to run/start

Path: tools/aurora_cli_wrapper.sh

#!/usr/bin/env bash
ROOT="$(cd "$(dirname "$0")/.." && pwd)"
PY="$(command -v python3 || command -v python || echo python3)"
case "$1" in
  start) $PY "$ROOT/aurora_os.py" start ;;
  stop) pkill -f aurora_os.py || echo "no process found";;
  status) ps aux | grep -E 'aurora_os.py|orchestrator' | grep -v grep ;;
  logs) tail -n 400 "$ROOT/aurora_logs/orchestrator.log";;
  *) echo "usage: $0 {start|stop|status|logs}"; exit 1 ;;
esac


chmod +x tools/aurora_cli_wrapper.sh

8) packaging/aurora_core.service — sample systemd unit for core

Path: packaging/aurora_core.service

[Unit]
Description=AuroraOS Core
After=network.target

[Service]
Type=simple
User=YOUR_USER
WorkingDirectory=/home/YOUR_USER/Aurora-x
ExecStart=/usr/bin/python3 /home/YOUR_USER/Aurora-x/aurora_os.py
Restart=on-failure
RestartSec=5

[Install]
WantedBy=multi-user.target


(adjust paths / user before installing)

9) README_AURORA_CORE.md — quick run & test

Path: README_AURORA_CORE.md

# Aurora Core — Quick start (PACK 1)

Requirements:
 - Python 3.11+
 - pip install psutil websockets

Install:
```bash
python3 -m venv .venv
source .venv/bin/activate
pip install --upgrade pip
pip install psutil websockets


Create example plugin:

mkdir -p aurora_modules/example-plugin
cp -r aurora_core/plugin_template/* aurora_modules/example-plugin/


Run core:

python3 aurora_os.py
# or ./tools/aurora_cli_wrapper.sh start


Check logs:

aurora_logs/orchestrator.log

aurora_logs/example-plugin.out.log

Edge test:

python3 aurora_core/edge_runtime.py
# in separate shell after core started


Notes:

For production, run behind systemd or in a container.

Use the Updater.stage_archive() and Updater.activate_staging() to test safe updates.

For heavy sandboxing use containers or cgroups.


---

# How to test immediately (copy/paste)

1. From project root:
```bash
# 1) install deps
python3 -m venv .venv
source .venv/bin/activate
pip install --upgrade pip
pip install psutil websockets

# 2) create plugin
mkdir -p aurora_modules/example-plugin
cp aurora_core/plugin_template/* aurora_modules/example-plugin/

# 3) run core
python3 aurora_os.py


In another terminal (after core started), test edge:

python3 aurora_core/edge_runtime.py
# It will connect to auroralink (ws://127.0.0.1:9801) and respond to pings.


Inspect logs:

tail -F aurora_logs/orchestrator.log aurora_logs/example-plugin.out.log

Security, sandboxing & production notes (must-read)

The code above uses best-effort local sandboxing. For real safety-critical systems ALWAYS:

Run plugins in containers (Docker) or real OS sandboxes (cgroups, seccomp, AppArmor).

Sign updates and verify signatures before activating.

Use hardware-backed keys (TPM, HSM) to sign and verify packages.

Enforce strict network firewall rules — AuroraLink should be LAN-only unless configured and secured.

For vehicles, satellites, aircraft: use the companion computer pattern (run Aurora in a container on a companion device; gateway to controllers must be certified and require human approvals).

Use monitoring & alerting (Prometheus + Grafana) in production.

Extension points (what PACK 2/3 will add)

After you verify this core, PACK 2/3 will add:

Full node + edge installers (native, docker, systemd, launchd)

Multi-arch Docker builds & Docker Compose

Edge runtime prebuilds for Raspberry Pi / Jetson (ARM)

Sign-and-verify updater tooling

More advanced AuroraLink (P2P discovery, mDNS, NAT traversal, DTLS)

PM2 / process manager integration (optional)

Dashboard + REST control (FastAPI) if you want embedded UI later