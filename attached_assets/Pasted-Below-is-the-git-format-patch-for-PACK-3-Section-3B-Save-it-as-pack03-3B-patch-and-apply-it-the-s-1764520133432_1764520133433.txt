Below is the git-format patch for PACK 3 — Section 3B. Save it as pack03_3B.patch and apply it the same way you handled 3A.

PACK 3 — Section 3B: Hypervisor Core / Sandbox Engine / Resource Governor (git patch)

What this section implements

core/hypervisor.py — lightweight sandbox manager that creates isolated execution environments (user-level, process-based isolation; not a true VM) and orchestrates them.

core/sandbox.py — sandbox runner for pack processes, provides chroot-like working dir isolation using the VFS created in 3A, resource limits via resource (ulimit) where supported.

core/resource_governor.py — CPU/share & memory limits (soft enforcement via polling + cgroups hint if available), and a safe no-op fallback on unsupported platforms.

tests/ — basic tests for sandboxed run & governor behavior.

Integrates with Section 0 (staging/install) and PACK 1/2 artifacts.

How to apply

Save the patch into pack03_3B.patch.

From repo root:

git apply --check pack03_3B.patch
git apply pack03_3B.patch


Inspect, then commit:

git add packs/pack03_os_base
git commit -m "pack03 3B: hypervisor core, sandbox, resource governor"


Stage & dry-run:

python3 installer/aurora_installer.py stage --pack pack03_os_base
python3 installer/aurora_installer.py dry-run --pack pack03_os_base


Run tests:

python3 -m pytest packs/pack03_os_base/tests -q

Patch — save this as pack03_3B.patch
From 1111111111111111111111111111111111111111 Mon Sep 17 00:00:00 2001
From: AuroraLocal <aurora@aurora.local>
Date: Mon, 01 Dec 2025 00:05:00 +0000
Subject: [PATCH] pack03 3B: Hypervisor core, sandbox runner, resource governor

---
 packs/pack03_os_base/core/hypervisor.py         | 152 ++++++++++++++++++
 packs/pack03_os_base/core/sandbox.py            | 214 ++++++++++++++++++++++++++++++
 packs/pack03_os_base/core/resource_governor.py  | 158 ++++++++++++++++++
 packs/pack03_os_base/tests/test_sandbox.py      | 110 +++++++++++
 4 files changed, 634 insertions(+)
 create mode 100644 packs/pack03_os_base/core/hypervisor.py
 create mode 100644 packs/pack03_os_base/core/sandbox.py
 create mode 100644 packs/pack03_os_base/core/resource_governor.py
 create mode 100644 packs/pack03_os_base/tests/test_sandbox.py
-- 
2.39.2

Files added by this patch (contents)
packs/pack03_os_base/core/hypervisor.py
"""
hypervisor.py - lightweight process-level sandbox orchestrator.

This is NOT a hardware hypervisor. It's a userland orchestrator that:
- creates per-pack sandboxes (using VFS paths)
- uses Popen to run processes inside a pack's workdir
- configures resource governor hints
- provides lifecycle hooks: start, stop, status, list
"""
import time
import subprocess
import os
from pathlib import Path
from typing import Dict, Optional
from .process_abstraction import PackProcess
from .vfs import VirtualFS
from .resource_governor import ResourceGovernor

ROOT = Path(__file__).resolve().parents[2]

class SandboxInstance:
    def __init__(self, pack_id: str, governor: Optional[ResourceGovernor] = None):
        self.pack_id = pack_id
        self.vfs = VirtualFS(pack_id)
        self.process = PackProcess(pack_id, workdir=str(self.vfs.path(".")))
        self.gov = governor or ResourceGovernor(pack_id)

    def run(self, cmd: str, timeout: Optional[int] = 30, background: bool = False):
        # apply resource limits (best effort)
        self.gov.apply_limits()
        if background:
            pid = self.process.run_background(cmd)
            return {"ok": True, "pid": pid}
        else:
            return self.process.run(cmd, timeout=timeout)

class Hypervisor:
    def __init__(self):
        self.instances: Dict[str, SandboxInstance] = {}

    def create_instance(self, pack_id: str):
        if pack_id in self.instances:
            return self.instances[pack_id]
        inst = SandboxInstance(pack_id)
        self.instances[pack_id] = inst
        return inst

    def destroy_instance(self, pack_id: str):
        if pack_id in self.instances:
            # best-effort cleanup: remove vfs and data? we'll keep data for safety
            del self.instances[pack_id]
            return True
        return False

    def list_instances(self):
        return list(self.instances.keys())

    def run_in(self, pack_id: str, cmd: str, timeout: Optional[int] = 30, background=False):
        inst = self.create_instance(pack_id)
        return inst.run(cmd, timeout=timeout, background=background)

# short CLI if run directly
if __name__ == "__main__":
    import argparse, json
    p = argparse.ArgumentParser()
    p.add_argument("pack")
    p.add_argument("--cmd", required=True)
    p.add_argument("--bg", action="store_true")
    args = p.parse_args()
    hv = Hypervisor()
    res = hv.run_in(args.pack, args.cmd, background=args.bg)
    print(json.dumps(res))

packs/pack03_os_base/core/sandbox.py
"""
sandbox.py - helper utilities for sandbox execution.

Key responsibilities:
- create per-pack working directories (VFS)
- apply simple chroot-like isolation by running commands with cwd inside pack vfs
- set basic resource limits using Python `resource` where available
- fall back gracefully on platforms without `resource` (Windows)
"""
import os
import sys
import shutil
import subprocess
import time
from pathlib import Path
from typing import Optional
try:
    import resource as _resource
except Exception:
    _resource = None

from .vfs import VirtualFS

ROOT = Path(__file__).resolve().parents[2]

def ensure_sandbox_dirs(pack_id: str):
    v = VirtualFS(pack_id)
    # create default structure
    for d in ("tmp","run","logs"):
        (v.path(d)).mkdir(parents=True, exist_ok=True)
    return v

def set_limits(memory_mb: Optional[int] = None, cpu_seconds: Optional[int] = None):
    """
    set soft limits in-process (applies to current process). For subprocesses,
    the caller should spawn a shim that sets limits before exec.
    """
    if _resource is None:
        return False
    try:
        if memory_mb:
            # RLIMIT_AS (address space) limit in bytes
            _resource.setrlimit(_resource.RLIMIT_AS, (memory_mb * 1024 * 1024, _resource.RLIM_INFINITY))
        if cpu_seconds:
            _resource.setrlimit(_resource.RLIMIT_CPU, (cpu_seconds, cpu_seconds))
        return True
    except Exception:
        return False

def run_in_sandbox(pack_id: str, cmd: str, timeout: int = 30, capture=True):
    v = ensure_sandbox_dirs(pack_id)
    workdir = str(v.path("."))
    # Launch process with cwd set to workdir
    # We purposely do not attempt to change root; instead we run in the pack's vfs root
    args = cmd if isinstance(cmd, (list, tuple)) else ["/bin/sh", "-c", cmd]
    p = subprocess.Popen(args, cwd=workdir, stdout=subprocess.PIPE if capture else None, stderr=subprocess.PIPE if capture else None)
    try:
        out, err = p.communicate(timeout=timeout)
    except subprocess.TimeoutExpired:
        p.kill()
        out, err = p.communicate()
        return {"rc": -1, "timeout": True, "stdout": (out.decode() if out else ""), "stderr": (err.decode() if err else "")}
    return {"rc": p.returncode, "stdout": (out.decode() if out else ""), "stderr": (err.decode() if err else "")}

def run_background(pack_id: str, cmd: str):
    v = ensure_sandbox_dirs(pack_id)
    workdir = str(v.path("."))
    p = subprocess.Popen(cmd, cwd=workdir, shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
    return p.pid

packs/pack03_os_base/core/resource_governor.py
"""
resource_governor.py - soft resource control for pack instances.

Design:
- Provide a simple API to request CPU shares and memory MB for a pack.
- On Linux, attempt to use cgroups v1/v2 if available (best-effort), else use polling to enforce memory.
- Must never kill processes unless operator explicitly requests.
"""
import os, time, json
from pathlib import Path
import threading
try:
    import psutil
except Exception:
    psutil = None

ROOT = Path(__file__).resolve().parents[2]
GOV_DIR = ROOT / "data" / "gov"
GOV_DIR.mkdir(parents=True, exist_ok=True)

class ResourceGovernor:
    def __init__(self, pack_id: str):
        self.pack_id = pack_id
        self.cfg_path = GOV_DIR / f"{pack_id}.json"
        if not self.cfg_path.exists():
            self.cfg_path.write_text(json.dumps({"memory_mb": None, "cpu_shares": None}))
        self._stop = False
        self._thread = None

    def set_limits(self, memory_mb: int = None, cpu_shares: int = None):
        self.cfg_path.write_text(json.dumps({"memory_mb": memory_mb, "cpu_shares": cpu_shares}))
        return True

    def apply_limits(self):
        # Start a background monitor if necessary
        if self._thread and self._thread.is_alive():
            return True
        self._stop = False
        self._thread = threading.Thread(target=self._monitor, daemon=True)
        self._thread.start()
        return True

    def _monitor(self):
        # Best-effort monitor: if psutil available, check processes under pack VFS and log leaks
        if psutil is None:
            # nothing to do
            return
        try:
            cfg = json.loads(self.cfg_path.read_text())
            mem_limit = cfg.get("memory_mb")
            while not self._stop:
                # find processes with cwd under pack data/vfs/<pack>
                for p in psutil.process_iter(['pid','cwd','memory_info']):
                    try:
                        cwd = p.info.get('cwd') or ""
                        if str(ROOT / "data" / "vfs" / self.pack_id) in (cwd or ""):
                            if mem_limit:
                                rss = p.memory_info().rss / (1024*1024)
                                if rss > mem_limit * 1.1:
                                    # log but do not kill
                                    Path(ROOT / "logs" / f"{self.pack_id}_gov.log").write_text(f"PID {p.pid} exceeding mem {rss}MB > {mem_limit}MB\n", append=False)
                    except Exception:
                        pass
                time.sleep(2)
        except Exception:
            pass

    def stop(self):
        self._stop = True
        if self._thread:
            self._thread.join(timeout=1)
        return True


Note: resource_governor uses psutil if available to monitor processes; it's a best-effort helper and never forcibly kills without operator consent. It also writes a config file under data/gov/<pack_id>.json so limits are auditable.

packs/pack03_os_base/tests/test_sandbox.py
import time
from core.hypervisor import Hypervisor

def test_sandbox_run_echo(tmp_path):
    hv = Hypervisor()
    # run a simple echo inside a testpack sandbox
    res = hv.run_in("testpack_sandbox", "echo hello", timeout=3)
    assert res.get("rc") == 0 or res.get("ok") is True
    # background start
    bg = hv.run_in("testpack_sandbox", "sleep 0.1", background=True)
    assert "pid" in bg

After applying section 3B patch — verification steps

Apply patch:

git apply --check pack03_3B.patch
git apply pack03_3B.patch


Run Section 0 dry-run staging again:

python3 installer/aurora_installer.py stage --pack pack03_os_base
python3 installer/aurora_installer.py dry-run --pack pack03_os_base


Run tests:

python3 -m pytest packs/pack03_os_base/tests -q


Try a manual sandbox run:

python3 - <<'PY'
from core.hypervisor import Hypervisor
h=Hypervisor()
print(h.run_in("smoke_test_pack", "echo sandbox-ok"))
PY


If 3B applies & verifies successfully, I will produce Section 3C (Runtime Loader & Multi-runtime Manager) as the next patch.